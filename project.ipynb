{"cells":[{"cell_type":"markdown","metadata":{"id":"EoC7XDIb2ODN"},"source":["# Server Execution"]},{"cell_type":"markdown","metadata":{"id":"DnEKy-rjnk8a"},"source":["## Connecting to server\n","The servers names are c-001 to c-008, you need to connect to them through GlobalProtect VPN (password from phone) or through SSH proxy at gate.tau.ac.il\n","I use `c-002.cs.tau.ac.il` because the `c-001` doesn't work: \\\\\n","`ssh <tau_username>@c-002.cs.tau.ac.il`\n","\n","### Paths on server\n","* Home directory: `/a/home/cc/students/cs/<tau_username>`, or `~`. \\\\\n","has a little storage so we don't use it\n","* Storage directory: `/vol/joberant_nobck/data/NLP_368307701_2223/`"]},{"cell_type":"markdown","metadata":{"id":"qWl9CxMUqRIS"},"source":["## Obtain code and data (RUN ONCE)\n","To download the code, and initialise a symbolic link to the data from Amit's directory (without copying it):\n","```\n","cd /vol/joberant_nobck/data/NLP_368307701_2223/<tau_username>\n","git clone https://www.github.com/pazbenitzhak/LyricsToChordsGenerator.git\n","cd LyricsToChordsGenerator\n","ln -s ../../amittal/dataset/ .\n","```"]},{"cell_type":"markdown","metadata":{"id":"BPZytqbZ3rNG"},"source":["## Setup environment\n","### Install MobaXterm\n","MobaXterm is a SSH client with FTP (insead of PuTTY + WinSCP), you can drug files in/out. \\\\\n","In addition, it supports SSH proxy, and remembers passwords - that means you can connect to the server in one click.\n","1. Download and install it from here:\n","https://mobaxterm.mobatek.net/download-home-edition.html\n","\n","2. Open the software, and create a new session using Sessions->New Session\n","\n","3. It will open a Session settings window, choose the SSH tab.\n","\n","4. Fill: \\\\\n","Remote host: c-002.cs.tau.ac.il \\\\\n","Set \"Specify username\", and write your tau username account \\\\\n","5. Under \"Network settings\", click on \"SSH gateway (jump host)\". Fill it: \\\\\n","Gateway host: gate.tau.ac.il \\\\\n","Username: <your tau username> \\\\\n","Press OK\n","\n","6. Press OK again to save your settings.\n","\n","7. Now in the left you will see the c-002.cs.tau.ac.il under \"User Sessions\". If you don't see, click the Start icon on the left and it will open your saved session.\n","\n","8. Double click c-002.cs.tau.ac.il session, and login with your TAU password (twice - for the gate, and for the server). \\\\\n","I recommend saving the password\n","\n","### Configure tmux\n","tmux (Terminal MUltiplieXer) is a linux software enables you to use multiple terminals in one screen.  \\\\\n","Default configuration has bind key Ctrl+b prefir for each command, I changed it Ctrl+a in my configuration. Default uses % for split - I changed it to s. Default uses \" for vertical split - I changed it to v. \\\\\n","To obtain my configuration execute:\n","```\n","cp /home/joberant/NLP_2223/assafgadish/.tmux.conf ~\n","```\n","Now apply it:\n","```\n","Ctrl+b\n",":source ~/.tmux.conf\n","```\n","Close the terminal and reop\n","(Note: if you already applied it once, the bind key has changed to Ctrl+a instead of Ctrl+b)\n","\n","### Create cache dir\n","In your personal directory create once a backup directory:\n","```\n","cd /home/joberant/NLP_2223/<tau_username>\n","mkdir cache_dirs\n","```\n","In EVERY terminal befor you execute the script, you must run:\n","```\n","export XDG_CACHE_HOME=/home/joberant/NLP_2223/<tau_username>/cache_dirs\n","export TORCH_HOME=/home/joberant/NLP_2223/<tau_username>/cache_dirs\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"5JOaj-0StCDJ"},"source":["## Terminal Utilities\n","### tmux\n","tmux (Terminal MUltiplieXer) is a linux software enables you to use multiple terminals in one screen.  \\\\\n","Default configuration has bind key Ctrl+b prefir for each command, I changed it Ctrl+a in my configuration. Default uses % for split - I changed it to s. Default uses \" for vertical split - I changed it to v. \\\\\n","To install my configuration see above \"Configure tmux\" (should execute once). \\\\\n","To run tmux:\n","```\n","tmux -2\n","```\n","\n","Full cheatsheet: https://tmuxcheatsheet.com/ \\\\\n","Basic cheatsheet: \\\\\n","* `Ctrl+a s`: split the window horizontally\n","* `Ctrl+a v`: split the window vertically\n","* `Ctrl+a <arrow>`: switch window in the direction of the arrow (right/left/up/down)\n","\n","### Useful linux commands\n","* `watch -n1 \"<command>\"`: executes <command> every 1 second (can adjust argument) and refresh the results\n","* `tail -F <filename>`: cat the file content and output appended data as file grows\n","\n","### Setup conda\n","Must be done in every new terminal, you can add it you your ~/.bashrc if you want. \\\\\n","Initialize conda and activate our environment using Assaf's installation and environment: (notice the '.' at the beginning): \\\\\n","```\n",". /home/joberant/NLP_2223/assafgadish/anaconda3/etc/profile.d/conda.sh\n","conda init bash\n","conda activate nlp_project\n","```\n","### Create cache dir\n","In your personal directory create once a backup directory:\n","```\n","cd /home/joberant/NLP_2223/<tau_username>\n","mkdir cache_dirs\n","```\n","In EVERY terminal befor you execute the script, you must run:\n","```\n","export XDG_CACHE_HOME=/home/joberant/NLP_2223/<tau_username>/cache_dirs\n","export TORCH_HOME=/home/joberant/NLP_2223/<tau_username>/cache_dirs\n","```\n","\n","### Using Slurm\n","Full TAU tutorial: https://www.cs.tau.ac.il/system/slurm\n","* `squeue --me` - show your jobs in the queue/executing\n","* `squeue` - show everyone's jobs in the queue/executing\n","* `sbatch project.slum` - execute the project\n","* `scancel <jobid>` - kill a job. obtrain its jobid from `squeue`\n"]},{"cell_type":"markdown","metadata":{"id":"qFwqJWF2vLRA"},"source":["## Running the project\n","1. Open tmux:\n","```\n","tmux -2\n","```\n","\n","2. Split the window to 4 terminals:\n","```\n","Ctrl+a s\n","Ctrl+a s\n","Ctrl+a <down>\n","Ctrl+a s\n","Ctrl+a s\n","```\n","3. Prepare helper terminals - in all the terminals CD to your dir:\n","In all the windows run:\n","```\n","cd /vol/joberant_nobck/data/NLP_368307701_2223/<your_tau_username>/LyricsToChordsGenerator\n","```\n","Choose 3 from the 4, and in each window run a different command:\n","```\n","tail -F results/project.out\n","```\n","```\n","tail -F results/project.err\n","```\n","```\n","watch -n1 \"squeue --me\"\n","```\n","4. **Prepare execution terminal**: \\\\\n","First initialise conda:\n","```\n",". /home/joberant/NLP_2223/assafgadish/anaconda3/etc/profile.d/conda.sh\n","conda init bash\n","conda activate nlp_project\n","```\n","Now make sure you created a cache dir (see Create a cache dir), and execute once in your current termianl within tmux:\n","```\n","export XDG_CACHE_HOME=/home/joberant/NLP_2223/<tau_username>/cache_dirs\n","export TORCH_HOME=/home/joberant/NLP_2223/<tau_username>/cache_dirs\n","```\n","Now the current terminal is ready and you can execute the project many times:\n","```\n","sbatch project.slurm\n","```"]},{"cell_type":"markdown","metadata":{"id":"YuEtSB8xp5X1"},"source":["# Colab Execution"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2646,"status":"ok","timestamp":1697458229988,"user":{"displayName":"Amit Tal","userId":"10134168706322622051"},"user_tz":-180},"id":"N16WrrxHayDE","outputId":"bb88189a-7696-4c02-ad80-b957e78396ad"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/nlp/project\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd '/content/drive/My Drive/nlp/project'"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35041,"status":"ok","timestamp":1697458265026,"user":{"displayName":"Amit Tal","userId":"10134168706322622051"},"user_tz":-180},"id":"2_u4FnkFa9Se","outputId":"3effbd14-f8e5-4b50-9a83-5a2234f36603"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n","     ---------------------------------------- 0.0/8.2 MB ? eta -:--:--\n","     ---------------------------------------- 0.0/8.2 MB 1.3 MB/s eta 0:00:07\n","     ---------------------------------------- 0.0/8.2 MB 1.3 MB/s eta 0:00:07\n","     ---------------------------------------- 0.0/8.2 MB 1.3 MB/s eta 0:00:07\n","     ---------------------------------------- 0.0/8.2 MB 1.3 MB/s eta 0:00:07\n","     ---------------------------------------- 0.0/8.2 MB 1.3 MB/s eta 0:00:07\n","     ---------------------------------------- 0.1/8.2 MB 327.7 kB/s eta 0:00:25\n","      --------------------------------------- 0.1/8.2 MB 385.0 kB/s eta 0:00:22\n","      --------------------------------------- 0.1/8.2 MB 385.0 kB/s eta 0:00:22\n","      --------------------------------------- 0.1/8.2 MB 385.0 kB/s eta 0:00:22\n","      --------------------------------------- 0.1/8.2 MB 277.4 kB/s eta 0:00:30\n","      --------------------------------------- 0.1/8.2 MB 293.9 kB/s eta 0:00:28\n","      --------------------------------------- 0.2/8.2 MB 317.5 kB/s eta 0:00:26\n","      --------------------------------------- 0.2/8.2 MB 336.6 kB/s eta 0:00:24\n","     - -------------------------------------- 0.2/8.2 MB 352.5 kB/s eta 0:00:23\n","     - -------------------------------------- 0.2/8.2 MB 367.4 kB/s eta 0:00:22\n","     - -------------------------------------- 0.2/8.2 MB 367.4 kB/s eta 0:00:22\n","     - -------------------------------------- 0.2/8.2 MB 367.4 kB/s eta 0:00:22\n","     - -------------------------------------- 0.3/8.2 MB 346.9 kB/s eta 0:00:23\n","     - -------------------------------------- 0.3/8.2 MB 358.6 kB/s eta 0:00:23\n","     - -------------------------------------- 0.4/8.2 MB 390.8 kB/s eta 0:00:21\n","     - -------------------------------------- 0.4/8.2 MB 388.7 kB/s eta 0:00:21\n","     - -------------------------------------- 0.4/8.2 MB 378.9 kB/s eta 0:00:21\n","     -- ------------------------------------- 0.4/8.2 MB 410.8 kB/s eta 0:00:19\n","     -- ------------------------------------- 0.5/8.2 MB 449.3 kB/s eta 0:00:18\n","     -- ------------------------------------- 0.5/8.2 MB 455.1 kB/s eta 0:00:17\n","     -- ------------------------------------- 0.5/8.2 MB 455.1 kB/s eta 0:00:17\n","     -- ------------------------------------- 0.5/8.2 MB 428.4 kB/s eta 0:00:18\n","     -- ------------------------------------- 0.6/8.2 MB 444.9 kB/s eta 0:00:18\n","     --- ------------------------------------ 0.7/8.2 MB 508.9 kB/s eta 0:00:15\n","     --- ------------------------------------ 0.7/8.2 MB 513.9 kB/s eta 0:00:15\n","     --- ------------------------------------ 0.8/8.2 MB 548.3 kB/s eta 0:00:14\n","     ---- ----------------------------------- 0.9/8.2 MB 585.5 kB/s eta 0:00:13\n","     ---- ----------------------------------- 1.0/8.2 MB 615.3 kB/s eta 0:00:12\n","     ----- ---------------------------------- 1.0/8.2 MB 648.9 kB/s eta 0:00:12\n","     ----- ---------------------------------- 1.1/8.2 MB 699.5 kB/s eta 0:00:11\n","     ------ --------------------------------- 1.2/8.2 MB 741.1 kB/s eta 0:00:10\n","     ------ --------------------------------- 1.4/8.2 MB 786.3 kB/s eta 0:00:09\n","     ------- -------------------------------- 1.5/8.2 MB 822.2 kB/s eta 0:00:09\n","     ------- -------------------------------- 1.5/8.2 MB 841.6 kB/s eta 0:00:08\n","     ------- -------------------------------- 1.6/8.2 MB 879.5 kB/s eta 0:00:08\n","     -------- ------------------------------- 1.8/8.2 MB 913.3 kB/s eta 0:00:08\n","     -------- ------------------------------- 1.8/8.2 MB 921.7 kB/s eta 0:00:07\n","     --------- ------------------------------ 1.9/8.2 MB 954.4 kB/s eta 0:00:07\n","     --------- ------------------------------ 2.0/8.2 MB 973.1 kB/s eta 0:00:07\n","     ---------- ----------------------------- 2.1/8.2 MB 992.7 kB/s eta 0:00:07\n","     ---------- ----------------------------- 2.2/8.2 MB 1.0 MB/s eta 0:00:06\n","     ----------- ---------------------------- 2.3/8.2 MB 1.1 MB/s eta 0:00:06\n","     ----------- ---------------------------- 2.4/8.2 MB 1.1 MB/s eta 0:00:06\n","     ------------ --------------------------- 2.5/8.2 MB 1.1 MB/s eta 0:00:06\n","     ------------ --------------------------- 2.6/8.2 MB 1.1 MB/s eta 0:00:05\n","     ------------- -------------------------- 2.8/8.2 MB 1.2 MB/s eta 0:00:05\n","     ------------- -------------------------- 2.8/8.2 MB 1.2 MB/s eta 0:00:05\n","     -------------- ------------------------- 2.9/8.2 MB 1.2 MB/s eta 0:00:05\n","     -------------- ------------------------- 3.1/8.2 MB 1.2 MB/s eta 0:00:05\n","     --------------- ------------------------ 3.2/8.2 MB 1.3 MB/s eta 0:00:04\n","     ---------------- ----------------------- 3.3/8.2 MB 1.3 MB/s eta 0:00:04\n","     ---------------- ----------------------- 3.5/8.2 MB 1.3 MB/s eta 0:00:04\n","     ----------------- ---------------------- 3.6/8.2 MB 1.3 MB/s eta 0:00:04\n","     ------------------ --------------------- 3.8/8.2 MB 1.4 MB/s eta 0:00:04\n","     ------------------- -------------------- 3.9/8.2 MB 1.4 MB/s eta 0:00:04\n","     ------------------- -------------------- 4.0/8.2 MB 1.4 MB/s eta 0:00:03\n","     -------------------- ------------------- 4.2/8.2 MB 1.5 MB/s eta 0:00:03\n","     --------------------- ------------------ 4.4/8.2 MB 1.5 MB/s eta 0:00:03\n","     --------------------- ------------------ 4.5/8.2 MB 1.5 MB/s eta 0:00:03\n","     ---------------------- ----------------- 4.7/8.2 MB 1.6 MB/s eta 0:00:03\n","     ----------------------- ---------------- 4.8/8.2 MB 1.6 MB/s eta 0:00:03\n","     ------------------------ --------------- 5.1/8.2 MB 1.6 MB/s eta 0:00:02\n","     ------------------------- -------------- 5.2/8.2 MB 1.6 MB/s eta 0:00:02\n","     ------------------------- -------------- 5.2/8.2 MB 1.6 MB/s eta 0:00:02\n","     -------------------------- ------------- 5.5/8.2 MB 1.7 MB/s eta 0:00:02\n","     -------------------------- ------------- 5.5/8.2 MB 1.7 MB/s eta 0:00:02\n","     --------------------------- ------------ 5.7/8.2 MB 1.7 MB/s eta 0:00:02\n","     ---------------------------- ----------- 5.8/8.2 MB 1.7 MB/s eta 0:00:02\n","     ----------------------------- ---------- 6.1/8.2 MB 1.8 MB/s eta 0:00:02\n","     ------------------------------ --------- 6.3/8.2 MB 1.8 MB/s eta 0:00:02\n","     ------------------------------- -------- 6.4/8.2 MB 1.8 MB/s eta 0:00:01\n","     ------------------------------- -------- 6.5/8.2 MB 1.8 MB/s eta 0:00:01\n","     --------------------------------- ------ 6.9/8.2 MB 1.9 MB/s eta 0:00:01\n","     --------------------------------- ------ 7.0/8.2 MB 1.9 MB/s eta 0:00:01\n","     ---------------------------------- ----- 7.1/8.2 MB 1.9 MB/s eta 0:00:01\n","     ----------------------------------- ---- 7.3/8.2 MB 1.9 MB/s eta 0:00:01\n","     ------------------------------------ --- 7.5/8.2 MB 2.0 MB/s eta 0:00:01\n","     ------------------------------------- -- 7.6/8.2 MB 2.0 MB/s eta 0:00:01\n","     ------------------------------------- -- 7.7/8.2 MB 2.0 MB/s eta 0:00:01\n","     ------------------------------------- -- 7.8/8.2 MB 2.0 MB/s eta 0:00:01\n","     -------------------------------------- - 7.9/8.2 MB 2.0 MB/s eta 0:00:01\n","     ---------------------------------------  8.1/8.2 MB 2.0 MB/s eta 0:00:01\n","     ---------------------------------------  8.2/8.2 MB 2.0 MB/s eta 0:00:01\n","     ---------------------------------------- 8.2/8.2 MB 2.0 MB/s eta 0:00:00\n","Requirement already satisfied: filelock in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.19.3\n","  Downloading huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\n","     ---------------------------------------- 0.0/330.3 kB ? eta -:--:--\n","     --------- ----------------------------- 81.9/330.3 kB 1.5 MB/s eta 0:00:01\n","     ----------------------- -------------- 204.8/330.3 kB 2.5 MB/s eta 0:00:01\n","     -------------------------------------- 330.3/330.3 kB 2.9 MB/s eta 0:00:00\n","Collecting regex!=2019.12.17\n","  Downloading regex-2023.12.25-cp310-cp310-win_amd64.whl (269 kB)\n","     ---------------------------------------- 0.0/269.5 kB ? eta -:--:--\n","     --------------------- ---------------- 153.6/269.5 kB 4.6 MB/s eta 0:00:01\n","     -------------------------------------- 269.5/269.5 kB 3.3 MB/s eta 0:00:00\n","Collecting safetensors>=0.3.1\n","  Downloading safetensors-0.4.1-cp310-none-win_amd64.whl (277 kB)\n","     ---------------------------------------- 0.0/277.3 kB ? eta -:--:--\n","     -------------------------------------- 277.3/277.3 kB 8.3 MB/s eta 0:00:00\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (21.3)\n","Collecting tqdm>=4.27\n","  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n","     ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n","     ---------------------------------------- 78.3/78.3 kB ? eta 0:00:00\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (1.22.3)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (2.27.1)\n","Collecting tokenizers<0.19,>=0.14\n","  Downloading tokenizers-0.15.0-cp310-none-win_amd64.whl (2.2 MB)\n","     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n","     --- ------------------------------------ 0.2/2.2 MB 5.9 MB/s eta 0:00:01\n","     --------- ------------------------------ 0.5/2.2 MB 6.3 MB/s eta 0:00:01\n","     ------------- -------------------------- 0.7/2.2 MB 5.7 MB/s eta 0:00:01\n","     -------------- ------------------------- 0.8/2.2 MB 4.6 MB/s eta 0:00:01\n","     ---------------- ----------------------- 0.9/2.2 MB 4.2 MB/s eta 0:00:01\n","     -------------------- ------------------- 1.1/2.2 MB 4.3 MB/s eta 0:00:01\n","     -------------------------- ------------- 1.5/2.2 MB 4.7 MB/s eta 0:00:01\n","     ---------------------------- ----------- 1.6/2.2 MB 4.6 MB/s eta 0:00:01\n","     --------------------------------- ------ 1.8/2.2 MB 4.7 MB/s eta 0:00:01\n","     ---------------------------------------  2.2/2.2 MB 5.0 MB/s eta 0:00:01\n","     ---------------------------------------- 2.2/2.2 MB 4.8 MB/s eta 0:00:00\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n","Collecting fsspec>=2023.5.0\n","  Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n","     ---------------------------------------- 0.0/169.0 kB ? eta -:--:--\n","     ------------------------------------ - 163.8/169.0 kB 5.0 MB/s eta 0:00:01\n","     -------------------------------------- 169.0/169.0 kB 3.4 MB/s eta 0:00:00\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: colorama in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers) (1.26.9)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers) (3.3)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers) (2021.10.8)\n","Installing collected packages: tqdm, safetensors, regex, fsspec, huggingface-hub, tokenizers, transformers\n","Successfully installed fsspec-2023.12.2 huggingface-hub-0.20.2 regex-2023.12.25 safetensors-0.4.1 tokenizers-0.15.0 tqdm-4.66.1 transformers-4.36.2\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n","[notice] To update, run: C:\\Users\\AssafGadish\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting jax<=0.3.16\n","  Downloading jax-0.3.16.tar.gz (1.0 MB)\n","     ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n","     - -------------------------------------- 0.0/1.0 MB 1.3 MB/s eta 0:00:01\n","     - -------------------------------------- 0.0/1.0 MB 1.3 MB/s eta 0:00:01\n","     ---- ----------------------------------- 0.1/1.0 MB 726.2 kB/s eta 0:00:02\n","     ---- ----------------------------------- 0.1/1.0 MB 726.2 kB/s eta 0:00:02\n","     ---- ----------------------------------- 0.1/1.0 MB 726.2 kB/s eta 0:00:02\n","     ----- ---------------------------------- 0.1/1.0 MB 532.5 kB/s eta 0:00:02\n","     --------- ------------------------------ 0.2/1.0 MB 835.2 kB/s eta 0:00:01\n","     ---------- ----------------------------- 0.3/1.0 MB 809.2 kB/s eta 0:00:01\n","     ------------- -------------------------- 0.4/1.0 MB 825.0 kB/s eta 0:00:01\n","     --------------- ------------------------ 0.4/1.0 MB 879.6 kB/s eta 0:00:01\n","     ------------------ --------------------- 0.5/1.0 MB 962.6 kB/s eta 0:00:01\n","     ---------------------- ----------------- 0.6/1.0 MB 1.0 MB/s eta 0:00:01\n","     ------------------------- -------------- 0.7/1.0 MB 1.1 MB/s eta 0:00:01\n","     ----------------------------- ---------- 0.8/1.0 MB 1.2 MB/s eta 0:00:01\n","     -------------------------------- ------- 0.8/1.0 MB 1.2 MB/s eta 0:00:01\n","     ------------------------------------- -- 1.0/1.0 MB 1.3 MB/s eta 0:00:01\n","     ---------------------------------------  1.0/1.0 MB 1.3 MB/s eta 0:00:01\n","     ---------------------------------------- 1.0/1.0 MB 1.2 MB/s eta 0:00:00\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: Could not find a version that satisfies the requirement jaxlib<=0.3.16 (from versions: 0.4.13, 0.4.14, 0.4.16, 0.4.17, 0.4.18, 0.4.19, 0.4.20, 0.4.21, 0.4.22, 0.4.23)\n","ERROR: No matching distribution found for jaxlib<=0.3.16\n","\n","[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n","[notice] To update, run: C:\\Users\\AssafGadish\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting torchtext==0.6\n","  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n","     ---------------------------------------- 0.0/64.2 kB ? eta -:--:--\n","     ------------------- -------------------- 30.7/64.2 kB 1.3 MB/s eta 0:00:01\n","     ------------------- -------------------- 30.7/64.2 kB 1.3 MB/s eta 0:00:01\n","     -------------------------------------- 64.2/64.2 kB 431.6 kB/s eta 0:00:00\n","Requirement already satisfied: tqdm in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torchtext==0.6) (4.66.1)\n","Requirement already satisfied: six in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torchtext==0.6) (1.16.0)\n","Requirement already satisfied: numpy in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torchtext==0.6) (1.22.3)\n","Requirement already satisfied: torch in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torchtext==0.6) (2.0.1)\n","Requirement already satisfied: requests in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torchtext==0.6) (2.27.1)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-win_amd64.whl (977 kB)\n","     ---------------------------------------- 0.0/977.5 kB ? eta -:--:--\n","     --- ----------------------------------- 92.2/977.5 kB 2.6 MB/s eta 0:00:01\n","     --- ----------------------------------- 92.2/977.5 kB 2.6 MB/s eta 0:00:01\n","     ----- ------------------------------ 143.4/977.5 kB 944.1 kB/s eta 0:00:01\n","     -------- ----------------------------- 225.3/977.5 kB 1.1 MB/s eta 0:00:01\n","     --------- ---------------------------- 256.0/977.5 kB 1.1 MB/s eta 0:00:01\n","     ------------- ------------------------ 358.4/977.5 kB 1.2 MB/s eta 0:00:01\n","     ----------------- -------------------- 440.3/977.5 kB 1.3 MB/s eta 0:00:01\n","     ------------------ ------------------- 481.3/977.5 kB 1.2 MB/s eta 0:00:01\n","     --------------------- ---------------- 553.0/977.5 kB 1.2 MB/s eta 0:00:01\n","     ------------------------ ------------- 634.9/977.5 kB 1.3 MB/s eta 0:00:01\n","     ---------------------------- --------- 737.3/977.5 kB 1.4 MB/s eta 0:00:01\n","     ------------------------------ ------- 788.5/977.5 kB 1.3 MB/s eta 0:00:01\n","     ---------------------------------- --- 890.9/977.5 kB 1.4 MB/s eta 0:00:01\n","     -------------------------------------  972.8/977.5 kB 1.4 MB/s eta 0:00:01\n","     -------------------------------------- 977.5/977.5 kB 1.4 MB/s eta 0:00:00\n","Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->torchtext==0.6) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->torchtext==0.6) (3.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->torchtext==0.6) (1.26.9)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->torchtext==0.6) (2021.10.8)\n","Requirement already satisfied: jinja2 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch->torchtext==0.6) (3.1.2)\n","Requirement already satisfied: filelock in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch->torchtext==0.6) (3.12.0)\n","Requirement already satisfied: sympy in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch->torchtext==0.6) (1.12)\n","Requirement already satisfied: typing-extensions in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch->torchtext==0.6) (4.9.0)\n","Requirement already satisfied: networkx in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch->torchtext==0.6) (2.8.8)\n","Requirement already satisfied: colorama in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm->torchtext==0.6) (0.4.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jinja2->torch->torchtext==0.6) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sympy->torch->torchtext==0.6) (1.3.0)\n","Installing collected packages: sentencepiece, torchtext\n","Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n","[notice] To update, run: C:\\Users\\AssafGadish\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Collecting datasets\n","  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n","     ---------------------------------------- 0.0/507.1 kB ? eta -:--:--\n","     -- ------------------------------------ 30.7/507.1 kB 1.3 MB/s eta 0:00:01\n","     -- ------------------------------------ 30.7/507.1 kB 1.3 MB/s eta 0:00:01\n","     ----- ------------------------------- 81.9/507.1 kB 657.6 kB/s eta 0:00:01\n","     ------- ---------------------------- 112.6/507.1 kB 819.2 kB/s eta 0:00:01\n","     ------- ---------------------------- 112.6/507.1 kB 819.2 kB/s eta 0:00:01\n","     ----------------- ------------------ 245.8/507.1 kB 942.1 kB/s eta 0:00:01\n","     ----------------- ------------------ 245.8/507.1 kB 942.1 kB/s eta 0:00:01\n","     ----------------- ------------------ 245.8/507.1 kB 942.1 kB/s eta 0:00:01\n","     -------------------------- --------- 368.6/507.1 kB 955.7 kB/s eta 0:00:01\n","     -------------------------- --------- 368.6/507.1 kB 955.7 kB/s eta 0:00:01\n","     ----------------------------- ------ 419.8/507.1 kB 846.3 kB/s eta 0:00:01\n","     ------------------------------------ 507.1/507.1 kB 963.0 kB/s eta 0:00:00\n","Collecting pyarrow>=8.0.0\n","  Downloading pyarrow-14.0.2-cp310-cp310-win_amd64.whl (24.6 MB)\n","     ---------------------------------------- 0.0/24.6 MB ? eta -:--:--\n","     ---------------------------------------- 0.1/24.6 MB 3.2 MB/s eta 0:00:08\n","     ---------------------------------------- 0.2/24.6 MB 2.4 MB/s eta 0:00:11\n","      --------------------------------------- 0.4/24.6 MB 2.9 MB/s eta 0:00:09\n","      --------------------------------------- 0.5/24.6 MB 2.6 MB/s eta 0:00:10\n","      --------------------------------------- 0.5/24.6 MB 2.6 MB/s eta 0:00:10\n","     - -------------------------------------- 0.7/24.6 MB 2.5 MB/s eta 0:00:10\n","     - -------------------------------------- 0.8/24.6 MB 2.5 MB/s eta 0:00:10\n","     - -------------------------------------- 0.9/24.6 MB 2.5 MB/s eta 0:00:10\n","     - -------------------------------------- 1.0/24.6 MB 2.5 MB/s eta 0:00:10\n","     - -------------------------------------- 1.1/24.6 MB 2.5 MB/s eta 0:00:10\n","     -- ------------------------------------- 1.3/24.6 MB 2.5 MB/s eta 0:00:10\n","     -- ------------------------------------- 1.4/24.6 MB 2.5 MB/s eta 0:00:10\n","     -- ------------------------------------- 1.4/24.6 MB 2.5 MB/s eta 0:00:10\n","     -- ------------------------------------- 1.6/24.6 MB 2.4 MB/s eta 0:00:10\n","     -- ------------------------------------- 1.7/24.6 MB 2.5 MB/s eta 0:00:09\n","     -- ------------------------------------- 1.7/24.6 MB 2.5 MB/s eta 0:00:09\n","     --- ------------------------------------ 1.9/24.6 MB 2.4 MB/s eta 0:00:10\n","     --- ------------------------------------ 2.0/24.6 MB 2.4 MB/s eta 0:00:10\n","     --- ------------------------------------ 2.1/24.6 MB 2.4 MB/s eta 0:00:10\n","     --- ------------------------------------ 2.2/24.6 MB 2.4 MB/s eta 0:00:10\n","     --- ------------------------------------ 2.4/24.6 MB 2.5 MB/s eta 0:00:10\n","     ---- ----------------------------------- 2.5/24.6 MB 2.5 MB/s eta 0:00:09\n","     ---- ----------------------------------- 2.7/24.6 MB 2.5 MB/s eta 0:00:09\n","     ---- ----------------------------------- 2.8/24.6 MB 2.5 MB/s eta 0:00:09\n","     ---- ----------------------------------- 3.0/24.6 MB 2.5 MB/s eta 0:00:09\n","     ---- ----------------------------------- 3.1/24.6 MB 2.6 MB/s eta 0:00:09\n","     ----- ---------------------------------- 3.2/24.6 MB 2.6 MB/s eta 0:00:09\n","     ----- ---------------------------------- 3.3/24.6 MB 2.6 MB/s eta 0:00:09\n","     ----- ---------------------------------- 3.4/24.6 MB 2.6 MB/s eta 0:00:09\n","     ----- ---------------------------------- 3.4/24.6 MB 2.5 MB/s eta 0:00:09\n","     ----- ---------------------------------- 3.6/24.6 MB 2.5 MB/s eta 0:00:09\n","     ------ --------------------------------- 3.8/24.6 MB 2.6 MB/s eta 0:00:09\n","     ------ --------------------------------- 3.9/24.6 MB 2.6 MB/s eta 0:00:09\n","     ------ --------------------------------- 4.1/24.6 MB 2.6 MB/s eta 0:00:08\n","     ------ --------------------------------- 4.2/24.6 MB 2.7 MB/s eta 0:00:08\n","     ------- -------------------------------- 4.4/24.6 MB 2.6 MB/s eta 0:00:08\n","     ------- -------------------------------- 4.4/24.6 MB 2.6 MB/s eta 0:00:08\n","     ------- -------------------------------- 4.4/24.6 MB 2.6 MB/s eta 0:00:08\n","     ------- -------------------------------- 4.4/24.6 MB 2.6 MB/s eta 0:00:08\n","     ------- -------------------------------- 4.4/24.6 MB 2.6 MB/s eta 0:00:08\n","     ------- -------------------------------- 4.7/24.6 MB 2.5 MB/s eta 0:00:08\n","     ------- -------------------------------- 4.7/24.6 MB 2.5 MB/s eta 0:00:09\n","     ------- -------------------------------- 4.9/24.6 MB 2.5 MB/s eta 0:00:09\n","     -------- ------------------------------- 5.1/24.6 MB 2.5 MB/s eta 0:00:08\n","     -------- ------------------------------- 5.1/24.6 MB 2.4 MB/s eta 0:00:08\n","     -------- ------------------------------- 5.2/24.6 MB 2.5 MB/s eta 0:00:08\n","     -------- ------------------------------- 5.4/24.6 MB 2.5 MB/s eta 0:00:08\n","     --------- ------------------------------ 5.6/24.6 MB 2.5 MB/s eta 0:00:08\n","     --------- ------------------------------ 5.7/24.6 MB 2.5 MB/s eta 0:00:08\n","     --------- ------------------------------ 5.8/24.6 MB 2.5 MB/s eta 0:00:08\n","     --------- ------------------------------ 6.0/24.6 MB 2.5 MB/s eta 0:00:08\n","     --------- ------------------------------ 6.1/24.6 MB 2.5 MB/s eta 0:00:08\n","     ---------- ----------------------------- 6.2/24.6 MB 2.5 MB/s eta 0:00:08\n","     ---------- ----------------------------- 6.4/24.6 MB 2.5 MB/s eta 0:00:08\n","     ---------- ----------------------------- 6.5/24.6 MB 2.6 MB/s eta 0:00:08\n","     ---------- ----------------------------- 6.5/24.6 MB 2.5 MB/s eta 0:00:08\n","     ---------- ----------------------------- 6.7/24.6 MB 2.5 MB/s eta 0:00:08\n","     ----------- ---------------------------- 6.8/24.6 MB 2.5 MB/s eta 0:00:07\n","     ----------- ---------------------------- 6.9/24.6 MB 2.5 MB/s eta 0:00:07\n","     ----------- ---------------------------- 7.1/24.6 MB 2.6 MB/s eta 0:00:07\n","     ----------- ---------------------------- 7.3/24.6 MB 2.6 MB/s eta 0:00:07\n","     ------------ --------------------------- 7.4/24.6 MB 2.6 MB/s eta 0:00:07\n","     ------------ --------------------------- 7.6/24.6 MB 2.6 MB/s eta 0:00:07\n","     ------------ --------------------------- 7.7/24.6 MB 2.6 MB/s eta 0:00:07\n","     ------------ --------------------------- 7.9/24.6 MB 2.6 MB/s eta 0:00:07\n","     ------------- -------------------------- 8.0/24.6 MB 2.6 MB/s eta 0:00:07\n","     ------------- -------------------------- 8.2/24.6 MB 2.6 MB/s eta 0:00:07\n","     ------------- -------------------------- 8.4/24.6 MB 2.6 MB/s eta 0:00:07\n","     ------------- -------------------------- 8.6/24.6 MB 2.7 MB/s eta 0:00:06\n","     -------------- ------------------------- 8.7/24.6 MB 2.7 MB/s eta 0:00:06\n","     -------------- ------------------------- 8.8/24.6 MB 2.7 MB/s eta 0:00:06\n","     -------------- ------------------------- 9.1/24.6 MB 2.7 MB/s eta 0:00:06\n","     -------------- ------------------------- 9.2/24.6 MB 2.7 MB/s eta 0:00:06\n","     --------------- ------------------------ 9.3/24.6 MB 2.7 MB/s eta 0:00:06\n","     --------------- ------------------------ 9.5/24.6 MB 2.7 MB/s eta 0:00:06\n","     --------------- ------------------------ 9.7/24.6 MB 2.7 MB/s eta 0:00:06\n","     --------------- ------------------------ 9.8/24.6 MB 2.7 MB/s eta 0:00:06\n","     ---------------- ----------------------- 10.0/24.6 MB 2.8 MB/s eta 0:00:06\n","     ---------------- ----------------------- 10.2/24.6 MB 2.8 MB/s eta 0:00:06\n","     ---------------- ----------------------- 10.3/24.6 MB 2.8 MB/s eta 0:00:06\n","     ----------------- ---------------------- 10.5/24.6 MB 2.8 MB/s eta 0:00:06\n","     ----------------- ---------------------- 10.7/24.6 MB 2.8 MB/s eta 0:00:05\n","     ----------------- ---------------------- 10.7/24.6 MB 2.8 MB/s eta 0:00:05\n","     ----------------- ---------------------- 10.7/24.6 MB 2.8 MB/s eta 0:00:06\n","     ----------------- ---------------------- 10.9/24.6 MB 2.8 MB/s eta 0:00:05\n","     ------------------ --------------------- 11.1/24.6 MB 2.8 MB/s eta 0:00:05\n","     ------------------ --------------------- 11.3/24.6 MB 2.8 MB/s eta 0:00:05\n","     ------------------ --------------------- 11.4/24.6 MB 2.9 MB/s eta 0:00:05\n","     ------------------ --------------------- 11.6/24.6 MB 2.9 MB/s eta 0:00:05\n","     ------------------- -------------------- 11.8/24.6 MB 2.9 MB/s eta 0:00:05\n","     ------------------- -------------------- 12.0/24.6 MB 3.0 MB/s eta 0:00:05\n","     ------------------- -------------------- 12.2/24.6 MB 3.0 MB/s eta 0:00:05\n","     -------------------- ------------------- 12.4/24.6 MB 3.0 MB/s eta 0:00:05\n","     -------------------- ------------------- 12.5/24.6 MB 3.0 MB/s eta 0:00:05\n","     -------------------- ------------------- 12.7/24.6 MB 3.0 MB/s eta 0:00:04\n","     --------------------- ------------------ 12.9/24.6 MB 3.0 MB/s eta 0:00:04\n","     --------------------- ------------------ 13.1/24.6 MB 3.0 MB/s eta 0:00:04\n","     --------------------- ------------------ 13.2/24.6 MB 3.0 MB/s eta 0:00:04\n","     --------------------- ------------------ 13.4/24.6 MB 3.0 MB/s eta 0:00:04\n","     ---------------------- ----------------- 13.6/24.6 MB 3.1 MB/s eta 0:00:04\n","     ---------------------- ----------------- 13.7/24.6 MB 3.1 MB/s eta 0:00:04\n","     ---------------------- ----------------- 13.9/24.6 MB 3.1 MB/s eta 0:00:04\n","     ---------------------- ----------------- 14.1/24.6 MB 3.1 MB/s eta 0:00:04\n","     ----------------------- ---------------- 14.2/24.6 MB 3.1 MB/s eta 0:00:04\n","     ----------------------- ---------------- 14.3/24.6 MB 3.1 MB/s eta 0:00:04\n","     ----------------------- ---------------- 14.6/24.6 MB 3.2 MB/s eta 0:00:04\n","     ----------------------- ---------------- 14.7/24.6 MB 3.3 MB/s eta 0:00:03\n","     ------------------------ --------------- 14.9/24.6 MB 3.3 MB/s eta 0:00:03\n","     ------------------------ --------------- 15.0/24.6 MB 3.3 MB/s eta 0:00:03\n","     ------------------------ --------------- 15.2/24.6 MB 3.3 MB/s eta 0:00:03\n","     ------------------------ --------------- 15.3/24.6 MB 3.4 MB/s eta 0:00:03\n","     ------------------------- -------------- 15.5/24.6 MB 3.4 MB/s eta 0:00:03\n","     ------------------------- -------------- 15.8/24.6 MB 3.4 MB/s eta 0:00:03\n","     ------------------------- -------------- 15.9/24.6 MB 3.4 MB/s eta 0:00:03\n","     -------------------------- ------------- 16.1/24.6 MB 3.4 MB/s eta 0:00:03\n","     -------------------------- ------------- 16.2/24.6 MB 3.4 MB/s eta 0:00:03\n","     -------------------------- ------------- 16.5/24.6 MB 3.5 MB/s eta 0:00:03\n","     --------------------------- ------------ 16.6/24.6 MB 3.5 MB/s eta 0:00:03\n","     --------------------------- ------------ 16.7/24.6 MB 3.5 MB/s eta 0:00:03\n","     --------------------------- ------------ 16.9/24.6 MB 3.5 MB/s eta 0:00:03\n","     --------------------------- ------------ 16.9/24.6 MB 3.5 MB/s eta 0:00:03\n","     --------------------------- ------------ 16.9/24.6 MB 3.5 MB/s eta 0:00:03\n","     --------------------------- ------------ 16.9/24.6 MB 3.5 MB/s eta 0:00:03\n","     --------------------------- ------------ 16.9/24.6 MB 3.5 MB/s eta 0:00:03\n","     --------------------------- ------------ 16.9/24.6 MB 3.5 MB/s eta 0:00:03\n","     --------------------------- ------------ 16.9/24.6 MB 3.5 MB/s eta 0:00:03\n","     ----------------------------- ---------- 18.2/24.6 MB 3.6 MB/s eta 0:00:02\n","     ----------------------------- ---------- 18.4/24.6 MB 3.6 MB/s eta 0:00:02\n","     ------------------------------ --------- 18.6/24.6 MB 3.6 MB/s eta 0:00:02\n","     ------------------------------ --------- 18.9/24.6 MB 3.7 MB/s eta 0:00:02\n","     ------------------------------ --------- 18.9/24.6 MB 3.6 MB/s eta 0:00:02\n","     ------------------------------- -------- 19.1/24.6 MB 3.6 MB/s eta 0:00:02\n","     ------------------------------- -------- 19.3/24.6 MB 3.6 MB/s eta 0:00:02\n","     ------------------------------- -------- 19.5/24.6 MB 3.7 MB/s eta 0:00:02\n","     ------------------------------- -------- 19.6/24.6 MB 3.7 MB/s eta 0:00:02\n","     -------------------------------- ------- 19.8/24.6 MB 3.6 MB/s eta 0:00:02\n","     -------------------------------- ------- 20.0/24.6 MB 3.7 MB/s eta 0:00:02\n","     -------------------------------- ------- 20.2/24.6 MB 3.7 MB/s eta 0:00:02\n","     -------------------------------- ------- 20.2/24.6 MB 3.7 MB/s eta 0:00:02\n","     -------------------------------- ------- 20.2/24.6 MB 3.6 MB/s eta 0:00:02\n","     --------------------------------- ------ 20.5/24.6 MB 3.6 MB/s eta 0:00:02\n","     --------------------------------- ------ 20.7/24.6 MB 3.6 MB/s eta 0:00:02\n","     --------------------------------- ------ 20.8/24.6 MB 3.6 MB/s eta 0:00:02\n","     ---------------------------------- ----- 21.0/24.6 MB 3.7 MB/s eta 0:00:01\n","     ---------------------------------- ----- 21.1/24.6 MB 3.7 MB/s eta 0:00:01\n","     ---------------------------------- ----- 21.3/24.6 MB 3.7 MB/s eta 0:00:01\n","     ----------------------------------- ---- 21.6/24.6 MB 3.7 MB/s eta 0:00:01\n","     ----------------------------------- ---- 21.6/24.6 MB 3.7 MB/s eta 0:00:01\n","     ----------------------------------- ---- 21.8/24.6 MB 3.6 MB/s eta 0:00:01\n","     ----------------------------------- ---- 22.0/24.6 MB 3.7 MB/s eta 0:00:01\n","     ------------------------------------ --- 22.2/24.6 MB 3.6 MB/s eta 0:00:01\n","     ------------------------------------ --- 22.4/24.6 MB 3.6 MB/s eta 0:00:01\n","     ------------------------------------ --- 22.6/24.6 MB 3.6 MB/s eta 0:00:01\n","     ------------------------------------- -- 22.8/24.6 MB 3.7 MB/s eta 0:00:01\n","     ------------------------------------- -- 22.9/24.6 MB 3.6 MB/s eta 0:00:01\n","     ------------------------------------- -- 23.0/24.6 MB 3.6 MB/s eta 0:00:01\n","     ------------------------------------- -- 23.3/24.6 MB 3.7 MB/s eta 0:00:01\n","     -------------------------------------- - 23.4/24.6 MB 3.6 MB/s eta 0:00:01\n","     -------------------------------------- - 23.6/24.6 MB 3.6 MB/s eta 0:00:01\n","     -------------------------------------- - 23.8/24.6 MB 3.6 MB/s eta 0:00:01\n","     -------------------------------------- - 24.0/24.6 MB 3.6 MB/s eta 0:00:01\n","     ---------------------------------------  24.2/24.6 MB 3.6 MB/s eta 0:00:01\n","     ---------------------------------------  24.4/24.6 MB 3.7 MB/s eta 0:00:01\n","     ---------------------------------------  24.5/24.6 MB 3.7 MB/s eta 0:00:01\n","     ---------------------------------------  24.6/24.6 MB 3.7 MB/s eta 0:00:01\n","     ---------------------------------------  24.6/24.6 MB 3.7 MB/s eta 0:00:01\n","     ---------------------------------------- 24.6/24.6 MB 3.5 MB/s eta 0:00:00\n","Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from datasets) (4.66.1)\n","Requirement already satisfied: filelock in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from datasets) (3.12.0)\n","Requirement already satisfied: pandas in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from datasets) (1.4.3)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from datasets) (0.20.2)\n","Requirement already satisfied: packaging in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from datasets) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from datasets) (6.0)\n","Collecting dill<0.3.8,>=0.3.0\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","     ---------------------------------------- 0.0/115.3 kB ? eta -:--:--\n","     -------------------------------------- 115.3/115.3 kB 6.6 MB/s eta 0:00:00\n","Collecting pyarrow-hotfix\n","  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Collecting xxhash\n","  Downloading xxhash-3.4.1-cp310-cp310-win_amd64.whl (29 kB)\n","Requirement already satisfied: requests>=2.19.0 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from datasets) (2.27.1)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","     ---------------------------------------- 0.0/134.8 kB ? eta -:--:--\n","     -------------------------------------- 134.8/134.8 kB 4.0 MB/s eta 0:00:00\n","Collecting fsspec[http]<=2023.10.0,>=2023.1.0\n","  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n","     ---------------------------------------- 0.0/166.4 kB ? eta -:--:--\n","     -------------------------------------  163.8/166.4 kB 5.0 MB/s eta 0:00:01\n","     -------------------------------------- 166.4/166.4 kB 5.0 MB/s eta 0:00:00\n","Collecting aiohttp\n","  Downloading aiohttp-3.9.1-cp310-cp310-win_amd64.whl (364 kB)\n","     ---------------------------------------- 0.0/364.6 kB ? eta -:--:--\n","     ----------- -------------------------- 112.6/364.6 kB 6.4 MB/s eta 0:00:01\n","     --------------------- ---------------- 204.8/364.6 kB 2.5 MB/s eta 0:00:01\n","     -------------------------------------  358.4/364.6 kB 3.2 MB/s eta 0:00:01\n","     -------------------------------------- 364.6/364.6 kB 2.8 MB/s eta 0:00:00\n","Requirement already satisfied: numpy>=1.17 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from datasets) (1.22.3)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.9.4-cp310-cp310-win_amd64.whl (76 kB)\n","     ---------------------------------------- 0.0/76.4 kB ? eta -:--:--\n","     ---------------------------------------- 76.4/76.4 kB 1.4 MB/s eta 0:00:00\n","Collecting async-timeout<5.0,>=4.0\n","  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl (50 kB)\n","     ---------------------------------------- 0.0/50.4 kB ? eta -:--:--\n","     ---------------------------------------- 50.4/50.4 kB 2.7 MB/s eta 0:00:00\n","Requirement already satisfied: attrs>=17.3.0 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from aiohttp->datasets) (23.1.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from packaging->datasets) (3.0.7)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.19.0->datasets) (3.3)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.19.0->datasets) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests>=2.19.0->datasets) (1.26.9)\n","Requirement already satisfied: colorama in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas->datasets) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, pyarrow-hotfix, pyarrow, multidict, fsspec, frozenlist, dill, async-timeout, yarl, multiprocess, aiosignal, aiohttp, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2023.12.2\n","    Uninstalling fsspec-2023.12.2:\n","      Successfully uninstalled fsspec-2023.12.2\n","Successfully installed aiohttp-3.9.1 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.16.1 dill-0.3.7 frozenlist-1.4.1 fsspec-2023.10.0 multidict-6.0.4 multiprocess-0.70.15 pyarrow-14.0.2 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n","[notice] To update, run: C:\\Users\\AssafGadish\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: chordparser in c:\\users\\assafgadish\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.4.2)\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n","[notice] To update, run: C:\\Users\\AssafGadish\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install transformers\n","!pip install \"jax<=0.3.16\" \"jaxlib<=0.3.16\"\n","!pip install torchtext==0.6\n","!pip install datasets\n","!pip install chordparser"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"QiDxn5DMa932"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\AssafGadish\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","from torchtext import data\n","from torchtext import datasets\n","\n","from transformers import BertTokenizer, BertModel, DistilBertForTokenClassification\n","\n","import numpy as np\n","\n","import time\n","import random\n","import functools\n","from datasets import load_dataset\n","from datasets import concatenate_datasets\n","from datasets import DatasetDict\n","from datasets import Dataset\n","\n","from tqdm.notebook import tqdm\n","\n","import pandas as pd\n","import itertools\n","import re\n","from pprint import pprint\n","\n","import os"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"AoYFE39na98d"},"outputs":[],"source":["from chord_tokenizer import ChordTokenizer\n","\n","def encode(input, max_input_length):\n","    ans = {'input_ids':[], 'token_type_ids':[], 'attention_mask':[]}\n","    for chords in input:\n","        chords = chords.split()\n","        tokens = [0]\n","        i=2\n","        for chord in chords:\n","            i+=1\n","            tokens.append(ChordTokenizer.tokenize(chord))\n","        tokens.append(0)\n","        padding = [0] * (max_input_length - i)\n","        ans['input_ids'].append(tokens + padding)\n","        ans['token_type_ids'].append([0 for _ in range(len(tokens))] + padding)\n","        ans['attention_mask'].append([1 for _ in range(len(tokens))] + padding)\n","    return ans\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1697458270411,"user":{"displayName":"Amit Tal","userId":"10134168706322622051"},"user_tz":-180},"id":"TxeiLCde_e5C","outputId":"d51d019c-12af-48ce-9b81-ab38c7fdab59"},"outputs":[{"ename":"NameError","evalue":"name 'my_tokenizer' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\AssafGadish\\OneDrive - mail.tau.ac.il\\NLP\\LyricsToChordsGenerator\\project.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/AssafGadish/OneDrive%20-%20mail.tau.ac.il/NLP/LyricsToChordsGenerator/project.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m my_tokenizer\u001b[39m.\u001b[39mtokenize(\u001b[39m'\u001b[39m\u001b[39mA\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[1;31mNameError\u001b[0m: name 'my_tokenizer' is not defined"]}],"source":["my_tokenizer.tokenize('A')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'cp' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\AssafGadish\\OneDrive - mail.tau.ac.il\\NLP\\LyricsToChordsGenerator\\project.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/AssafGadish/OneDrive%20-%20mail.tau.ac.il/NLP/LyricsToChordsGenerator/project.ipynb#X15sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mChord \u001b[39m\u001b[39m{\u001b[39;00mchord_name\u001b[39m}\u001b[39;00m\u001b[39m in C major: \u001b[39m\u001b[39m{\u001b[39;00mchordparser\u001b[39m.\u001b[39mChord(chord_name)\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mC_major\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/AssafGadish/OneDrive%20-%20mail.tau.ac.il/NLP/LyricsToChordsGenerator/project.ipynb#X15sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m song \u001b[39m=\u001b[39m SongsChords(\u001b[39m'\u001b[39m\u001b[39mG B C Cm\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/AssafGadish/OneDrive%20-%20mail.tau.ac.il/NLP/LyricsToChordsGenerator/project.ipynb#X15sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m best_scale \u001b[39m=\u001b[39m song\u001b[39m.\u001b[39;49mfind_best_scale()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/AssafGadish/OneDrive%20-%20mail.tau.ac.il/NLP/LyricsToChordsGenerator/project.ipynb#X15sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbest scale is \u001b[39m\u001b[39m{\u001b[39;00mbest_scale\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n","\u001b[1;32mc:\\Users\\AssafGadish\\OneDrive - mail.tau.ac.il\\NLP\\LyricsToChordsGenerator\\project.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/AssafGadish/OneDrive%20-%20mail.tau.ac.il/NLP/LyricsToChordsGenerator/project.ipynb#X15sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m best_scale \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/AssafGadish/OneDrive%20-%20mail.tau.ac.il/NLP/LyricsToChordsGenerator/project.ipynb#X15sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m scale_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_chords[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mquality\u001b[39m.\u001b[39mvalue \u001b[39m# 'major' or 'minor'\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/AssafGadish/OneDrive%20-%20mail.tau.ac.il/NLP/LyricsToChordsGenerator/project.ipynb#X15sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m best_scale \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m([ScaleMatch(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcp\u001b[39m.\u001b[39mcreate_scale(root, scale_type), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_chords, cp) \u001b[39mfor\u001b[39;00m root \u001b[39min\u001b[39;00m NOTE_TO_TOKEN\u001b[39m.\u001b[39mkeys()])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/AssafGadish/OneDrive%20-%20mail.tau.ac.il/NLP/LyricsToChordsGenerator/project.ipynb#X15sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m \u001b[39mreturn\u001b[39;00m best_scale\n","\u001b[1;32mc:\\Users\\AssafGadish\\OneDrive - mail.tau.ac.il\\NLP\\LyricsToChordsGenerator\\project.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/AssafGadish/OneDrive%20-%20mail.tau.ac.il/NLP/LyricsToChordsGenerator/project.ipynb#X15sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m best_scale \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/AssafGadish/OneDrive%20-%20mail.tau.ac.il/NLP/LyricsToChordsGenerator/project.ipynb#X15sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m scale_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_chords[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mquality\u001b[39m.\u001b[39mvalue \u001b[39m# 'major' or 'minor'\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/AssafGadish/OneDrive%20-%20mail.tau.ac.il/NLP/LyricsToChordsGenerator/project.ipynb#X15sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m best_scale \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m([ScaleMatch(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcp\u001b[39m.\u001b[39mcreate_scale(root, scale_type), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_chords, cp) \u001b[39mfor\u001b[39;00m root \u001b[39min\u001b[39;00m NOTE_TO_TOKEN\u001b[39m.\u001b[39mkeys()])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/AssafGadish/OneDrive%20-%20mail.tau.ac.il/NLP/LyricsToChordsGenerator/project.ipynb#X15sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m \u001b[39mreturn\u001b[39;00m best_scale\n","\u001b[1;31mNameError\u001b[0m: name 'cp' is not defined"]}],"source":["import chordparser\n","from chord_tokenizer import NOTE_TO_TOKEN\n","# from pychord import Chord\n","# from pychord.constants import VAL_NOTE_DICT, NOTE_VAL_DICT\n","# from pychord.constants.scales import RELATIVE_KEY_DICT\n","\n","\n","class ScaleMatchCriteria(object):\n","    def __init__(self, scale, chords, cp):\n","        self.scale = scale\n","        self.chords = chords\n","        self.cp = cp\n","        self.score = self.calc_score()\n","\n","    def calc_score(self):\n","        raise NotImplementedError\n","    \n","class DiatomicMatchCriteria(ScaleMatchCriteria):\n","    def calc_score(self):\n","        matches_count = len([self.cp.analyse_diatomic(c, self.scale) for c in self.chords])\n","        score = matches_count / len(self.chords)\n","        return score\n","\n","class FirstChordMatchCriteria(ScaleMatchCriteria):\n","    def calc_score(self):\n","        results = self.cp.analyse_diatonic(self.chords[0], self.scale)\n","        if results:  # diatonic\n","            function = results[0][0].root  # just show roman notation\n","            if function == 'i':\n","                return 1\n","            if function == 'v':\n","                return 0.5\n","        return 0\n","    \n","class LastChordMatchCriteria(ScaleMatchCriteria):\n","    def calc_score(self):\n","        results = self.cp.analyse_diatonic(self.chords[-1], self.scale)\n","        if results:  # diatonic\n","            function = results[0][0].root  # just show roman notation\n","            if function == 'i':\n","                return 1\n","        return 0\n","    \n","class ScaleMatch(object):\n","    def __init__(self, scale, chords, cp, criterias=None):\n","        if not criterias:\n","            criterias = list()\n","        self.criterias = [\n","            DiatomicMatchCriteria(scale, chords, cp),\n","            FirstChordMatchCriteria(scale, chords, cp),\n","            LastChordMatchCriteria(scale, chords, cp)\n","        ]\n","        self.scale = scale\n","        self.chords = chords\n","        self.cp = cp\n","        self.score = sum([criteria.score() for criteria in self.criterias])\n","\n","    def __lt__(self, other):\n","        if self.score != other.score:\n","            return self.score < other.score\n","        \n","        if self.chords[0].root != self.scale.root:\n","            if self.chords[0].root == self.chords[0].root:\n","                return False\n","            elif self.scale.root == self.chords[0].root:\n","                return True\n","   \n","        # Equal\n","        return False\n","    \n","    def __le__(self, other):\n","        if self.score != other.score:\n","            return self.score <= other.score\n","        \n","        if self.chords[0].root != self.scale.root:\n","            if self.chords[0].root == self.chords[0].root:\n","                return False\n","            elif self.scale.root == self.chords[0].root:\n","                return True\n","   \n","        # Equal\n","        return True\n","        \n","    def __gt__(self, other):\n","        if self.score != other.score:\n","            return self.score > other.score\n","        \n","        if self.chords[0].root != self.scale.root:\n","            if self.chords[0].root == self.chords[0].root:\n","                return True\n","            elif self.scale.root == self.chords[0].root:\n","                return False\n","   \n","        # Equal\n","        return False\n","        \n","    def __ge__(self, other):\n","        if self.score != other.score:\n","            return self.score > other.score\n","        \n","        if self.chords[0].root != self.scale.root:\n","            if self.chords[0].root == self.chords[0].root:\n","                return True\n","            elif self.scale.root == self.chords[0].root:\n","                return False\n","   \n","        # Equal\n","        return True\n","    \n","    def __cmp__(self, other):\n","        return self.scale == other._scale and self.chords == other._chords\n","    \n","    def __str__(self):\n","        return f'[ScaleMatch: {self.scale} score={self.score}]'\n","\n","class SongsChords(object):\n","    def __init__(self, chords: list):\n","        self.cp = chordparser.Parser()\n","        self._raw_chords = chords\n","        self._chords = [self.cp.create_chord(c) for c in chords.split()]\n","\n","    def find_best_scale(self):\n","        # The scale will be major/minor depending on the type of the first note\n","        best_score = 0\n","        best_scale = None\n","        scale_type = self._chords[0].quality.value # 'major' or 'minor'\n","        best_scale = max([ScaleMatch(self.cp.create_scale(root, scale_type), self._chords, cp) for root in NOTE_TO_TOKEN.keys()])\n","        \n","        return best_scale\n","\n","\n","def check_chord(chord_name):\n","    print(f'Chord {chord_name} in C major: {chordparser.Chord(chord_name) in C_major}')\n","\n","song = SongsChords('G B C Cm')\n","best_scale = song.find_best_scale()\n","print(f'best scale is {best_scale}')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"XKGE_v1rLZqI"},"outputs":[{"name":"stderr","output_type":"stream","text":["tokenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<?, ?B/s]\n","C:\\Users\\AssafGadish\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\AssafGadish\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n","vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.65MB/s]\n","tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 2.46MB/s]\n","config.json: 100%|██████████| 570/570 [00:00<?, ?B/s] \n"]}],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","init_token = tokenizer.cls_token\n","pad_token = tokenizer.pad_token\n","unk_token = tokenizer.unk_token\n","\n","init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n","pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n","unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n","\n","max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n","\n","def cut_and_convert_to_id(tokens, tokenizer, max_input_length):\n","    tokens = tokens[:max_input_length-1]\n","    tokens = tokenizer.convert_tokens_to_ids(tokens)\n","    return tokens\n","\n","def cut_to_max_length(tokens, max_input_length):\n","    tokens = tokens[:max_input_length-1]\n","    return tokens\n","\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"f3PWTUM7t-Bj"},"outputs":[],"source":["if os.path.isfile('dataset/chords_and_lyrics_en.pkl'):\n","  english_chords = pd.read_pickle('dataset/chords_and_lyrics_en.pkl')\n","else:\n","  data = pd.read_pickle('dataset/chords_and_lyrics.pkl')\n","  english_chords = data[data['lang'] == 'en']\n","  english_chords.to_pickle('dataset/chords_and_lyrics_en.pkl')\n","  english_chords.to_csv('dataset/chords_and_lyrics_en.csv')\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["{0: '\\nCapo on 3rd fret\\n\\t  \\t\\t ',\n"," 1: '',\n"," 2: 'Verse 1:',\n"," 4: '  Do you love the rain, does it make you dance ',\n"," 6: \"When you're drunk with your friends at a party? \",\n"," 8: \"  What's your favorite song, does it make you smile? \",\n"," 10: 'Do you think of me? ',\n"," 11: '',\n"," 12: 'Pre-Chorus',\n"," 14: \"When you close your eyes, tell me what are you dreamin'? \",\n"," 16: 'Everything, I -- wanna know it all ',\n"," 17: '',\n"," 18: '',\n"," 20: \"I'd spend ten thousand hours and ten thousand more \",\n"," 22: \"Oh if that's what it takes to learn that sweet heart of yours \",\n"," 24: \"And I might never get there, but I'm gonna try \",\n"," 26: \"If it's ten thousand hours or the rest of my life \",\n"," 28: \"I'm gonna love you (oooh ooh-oooh ooh-ooh) \",\n"," 29: '',\n"," 30: 'Verse 2:',\n"," 32: '  Do you miss the road that you grew up on? ',\n"," 34: 'Did you get your middle name from your grandma? ',\n"," 36: '  When you think about your forever now ',\n"," 38: 'Do you think of me? ',\n"," 39: '',\n"," 40: 'Pre-Chorus',\n"," 42: \"When you close your eyes, tell me what are you dreamin'? \",\n"," 44: 'Everything, I -- wanna know it all ',\n"," 45: '',\n"," 46: '',\n"," 48: \"I'd spend ten thousand hours and ten thousand more \",\n"," 50: \"Oh if that's what it takes to learn that sweet heart of yours \",\n"," 52: \"And I might never get there, but I'm gonna try \",\n"," 54: \"If it's ten thousand hours or the rest of my life \",\n"," 56: \"I'm gonna love you (oooh ooh-oooh ooh-ooh) \",\n"," 58: \"I'm gonna love you (oooh ooh-oooh ooh-ooh) \",\n"," 59: '',\n"," 62: '   Ooh, want the good and the bad, everything in between ',\n"," 64: '   Ooh, gotta cure my curiosity ',\n"," 65: '',\n"," 66: 'Ooh, yeah ',\n"," 67: '',\n"," 68: '',\n"," 70: \"I'd spend ten thousand hours and ten thousand more \",\n"," 72: \"Oh if that's what it takes to learn that sweet heart of yours (sweet heart of yours) \",\n"," 74: \"And I might never get there, but I'm gonna try (yeah) \",\n"," 76: \"If it's ten thousand hours or the rest of my life \",\n"," 78: \"I'm gonna love you (oooh ooh-oooh ooh-ooh) \",\n"," 80: \"I'm gonna love you (oooh ooh-oooh) yeah (ooh-ooh) \",\n"," 81: '',\n"," 82: 'Final ',\n"," 83: '',\n"," 85: 'And I-- (do you love the rain, does it make you dance?) ',\n"," 87: \"I'm gonna love you (I'm gonna love you) \",\n"," 90: '\\t\\t  \\n'}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["a1,a2 = english_chords['lyrics'].iloc[:2]\n","a1"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"z7_QOBBw91Dx"},"outputs":[],"source":["def find_word_in_ind(ind, line):\n","  last_ind = ind\n","  for i in range(ind, len(line)):\n","    if line[i].isspace():\n","      break\n","    last_ind = i\n","  return line[ind:last_ind+1]"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ZliRUsVi4ih1"},"outputs":[],"source":["def find_word_to_chord_ind(chord_ind, line):\n","    letter_ind = min(chord_ind, len(line)-1)\n","    if line[letter_ind].isspace():\n","      is_found = False\n","      for i in range(letter_ind,len(line)):\n","        if not line[i].isspace():\n","          letter_ind = i\n","          is_found = True\n","          break\n","      if is_found == False:\n","        for i in range(letter_ind,-1,-1):\n","          if not line[i].isspace():\n","            letter_ind = i\n","            is_found = True\n","            break\n","        if is_found == True:\n","          is_space_found = False\n","          for i in range(letter_ind,-1,-1):\n","            if line[i].isspace():\n","              letter_ind = i\n","              is_space_found=True\n","              break\n","          if is_space_found == True:\n","            letter_ind = letter_ind+1\n","          else:\n","            letter_ind = 0\n","    else:\n","      is_space_found = False\n","      for i in range(letter_ind,-1,-1):\n","        if line[i].isspace():\n","          letter_ind = i\n","          is_space_found=True\n","          break\n","      if is_space_found == True:\n","        letter_ind = letter_ind+1\n","      else:\n","        letter_ind = 0\n","    return find_word_in_ind(letter_ind, line)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"-hBbH_LVOmn8"},"outputs":[],"source":["def find_ind_word_to_chord_ind(chord_ind, line):\n","  count = 0\n","  letter_ind = min(chord_ind, len(line)-1)\n","  is_space = line[letter_ind].isspace()\n","  if is_space:\n","    count +=1\n","  for i in range(letter_ind,-1,-1):\n","    if is_space == False and line[i].isspace() == True:\n","      count +=1\n","    is_space = line[i].isspace()\n","  return count\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":446219,"status":"ok","timestamp":1697458719404,"user":{"displayName":"Amit Tal","userId":"10134168706322622051"},"user_tz":-180},"id":"tZBHsAmbD8J4","outputId":"586d7c7e-c42d-4c26-e11b-4f76be3dd77c"},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","1000\n","2000\n","3000\n","4000\n","5000\n","6000\n","7000\n","8000\n","9000\n","10000\n","11000\n","12000\n","13000\n","14000\n","15000\n","16000\n","17000\n","18000\n","19000\n","20000\n","21000\n","22000\n","23000\n","24000\n","25000\n","26000\n","27000\n","28000\n","29000\n","30000\n","31000\n","32000\n","33000\n","34000\n","35000\n","36000\n","37000\n","38000\n","39000\n","40000\n","41000\n","42000\n","43000\n","44000\n","45000\n","46000\n","47000\n","48000\n","49000\n","50000\n","51000\n","52000\n","53000\n","54000\n","55000\n","56000\n","57000\n","58000\n","59000\n","60000\n","61000\n","62000\n","63000\n","64000\n","65000\n","66000\n","67000\n","68000\n","69000\n","70000\n","71000\n","72000\n","73000\n","74000\n","75000\n","76000\n","77000\n","78000\n","79000\n","80000\n","{'input_ids': [101, 1030, 6178, 2080, 2006, 3822, 10424, 3388, 1030, 7893, 1015, 1024, 1030, 2079, 2017, 2293, 1996, 4542, 1010, 2515, 2009, 2191, 2017, 3153, 1030, 2043, 2017, 1005, 2128, 7144, 2007, 2115, 2814, 2012, 1037, 2283, 1029, 1030, 2054, 1005, 1055, 2115, 5440, 2299, 1010, 2515, 2009, 2191, 2017, 2868, 1029, 1030, 2079, 2017, 2228, 1997, 2033, 1029, 1030, 3653, 1011, 7165, 1030, 2043, 2017, 2485, 2115, 2159, 1010, 2425, 2033, 2054, 2024, 2017, 3959, 2378, 1005, 1029, 1030, 2673, 1010, 1045, 1011, 1011, 10587, 2113, 2009, 2035, 1030, 1030, 1045, 1005, 1040, 5247, 2702, 4595, 2847, 1998, 2702, 4595, 2062, 1030, 2821, 2065, 2008, 1005, 1055, 2054, 2009, 3138, 2000, 4553, 2008, 4086, 2540, 1997, 6737, 1030, 1998, 1045, 2453, 2196, 2131, 2045, 1010, 2021, 1045, 1005, 1049, 6069, 3046, 1030, 2065, 2009, 1005, 1055, 2702, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 0, 34, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 130, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 34, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 2251, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 2251, 0, 0, 0, 39, 0, 0, 0, 0, 0, 130, 0, 2251, 0, 39, 0, 0, 0, 0, 0, 0, 0, 130, 0, 0, 2251, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 2251, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 2251, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 2251, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 0, 34, 0, 0, 0, 0, 0, 39, 0, 0, 0, 0, 0, 130, 0, 0, 0, 0, 0, 0, 0, 130, 0, 0, 34, 0, 0, 39, 0, 0, 0, 0, 130, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 2251, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 2251, 0, 0, 0, 39, 0, 0, 0, 0, 0, 130, 0, 2251, 0, 39, 0, 0, 0, 0, 0, 0, 0, 130, 0, 0, 2251, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 2251, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 2251, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 2251, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 2251, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2186, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2186, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 2251, 0, 39, 0, 0, 0, 0, 0, 0, 0, 130, 0, 0, 2251, 0, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 2251, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 2251, 0, 0, 39, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 2251, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 130, 0, 2251, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[101, 1030, 6178, 2080, 2006, 3822, 10424, 3388, 1030, 7893, 1015, 1024, 1030, 2079, 2017, 2293, 1996, 4542, 1010, 2515, 2009, 2191, 2017, 3153, 1030, 2043, 2017, 1005, 2128, 7144, 2007, 2115, 2814, 2012, 1037, 2283, 1029, 1030, 2054, 1005, 1055, 2115, 5440, 2299, 1010, 2515, 2009, 2191, 2017, 2868, 1029, 1030, 2079, 2017, 2228, 1997, 2033, 1029, 1030, 3653, 1011, 7165, 1030, 2043, 2017, 2485, 2115, 2159, 1010, 2425, 2033, 2054, 2024, 2017, 3959, 2378, 1005, 1029, 1030, 2673, 1010, 1045, 1011, 1011, 10587, 2113, 2009, 2035, 1030, 1030, 1045, 1005, 1040, 5247, 2702, 4595, 2847, 1998, 2702, 4595, 2062, 1030, 2821, 2065, 2008, 1005, 1055, 2054, 2009, 3138, 2000, 4553, 2008, 4086, 2540, 1997, 6737, 1030, 1998, 1045, 2453, 2196, 2131, 2045, 1010, 2021, 1045, 1005, 1049, 6069, 3046, 1030, 2065, 2009, 1005, 1055, 2702, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["lyrics = english_chords[\"lyrics\"]\n","chords = english_chords[\"chords\"]\n","annotated_lyrics = []\n","annotated_chords = []\n","annotated_lyrics_input_ids = []\n","annotated_lyrics_token_type_ids = []\n","annotated_lyrics_attention_mask = []\n","annotated_chords_chords_id = []\n","data = []\n","for i in range(len(lyrics)):\n","  row = {}\n","  if i % 1000 == 0:\n","    print(i)\n","  if i not in lyrics or i not in chords:\n","    continue\n","  lyric = lyrics[i]\n","  chord = chords[i]\n","  text = \"\"\n","  for j in range(len(lyric)):\n","    text += \" @ \"                 # new line sign\n","    if 2*j not in lyric:\n","      continue\n","    line = lyric[2*j]\n","    if len(line)==0:\n","      continue\n","    line = line.replace('\\n', '')\n","    line = line.replace('\\t', '')\n","    words_in_line = line.split()\n","    if len(words_in_line) == 0:\n","      continue\n","    text += line\n","\n","  tokenized_text = tokenizer(cut_to_max_length(text, max_input_length),\n","                         padding='max_length',\n","                         truncation=True)\n","\n","  tokenized_chords = list(np.zeros(len(tokenized_text['input_ids']), int))\n","  annotated_lyrics_input_ids.append(tokenized_text['input_ids'])\n","  annotated_lyrics_token_type_ids.append(tokenized_text['token_type_ids'])\n","  annotated_lyrics_attention_mask.append(tokenized_text['attention_mask'])\n","  row['input_ids'] = tokenized_text['input_ids']\n","  row['token_type_ids'] = tokenized_text['token_type_ids']\n","  row['attention_mask'] = tokenized_text['attention_mask']\n","\n","  words_in_text = text.split()\n","  start_from_ind = 1\n","  for j in range(len(lyric)):\n","    if 2*j not in lyric:\n","      continue\n","    line = lyric[2*j]\n","    if len(line)==0:\n","      continue\n","    line = line.replace('\\n', '')\n","    line = line.replace('\\t', '')\n","    words_in_line = line.split()\n","    tokenized_line = tokenizer(cut_to_max_length(line, max_input_length))\n","    if len(words_in_line) == 0:\n","      continue\n","\n","    if (2*j-1) in chord:\n","      line_chords = chord[2*j-1]\n","      line_chords = line_chords.replace('\\n', '')\n","      line_chords = line_chords.replace('\\t', '')\n","      chords_in_line = line_chords.split()\n","\n","      for chord_in_line in chords_in_line:\n","        chord_ind = line_chords.find(chord_in_line)\n","        #word = find_word_to_chord_ind(chord_ind, line)\n","        #word_ind = words_in_line.index(word)\n","        word_ind = find_ind_word_to_chord_ind(chord_ind, line)\n","        ind = start_from_ind + word_ind\n","        if ind < max_input_length:\n","          tokenized_chords[ind] = my_tokenizer.tokenize(chord_in_line)\n","    start_from_ind += len(tokenized_line['input_ids'])-2 + 1\n","    #start_from_ind += len(words_in_line) +1\n","  annotated_lyrics.append(tokenized_text)\n","  annotated_chords.append(tokenized_chords)\n","  annotated_chords_chords_id.append(tokenized_chords)\n","  row['labels'] = tokenized_chords\n","  data.append(row)\n","\n","print(annotated_lyrics[0])\n","print(annotated_chords[0])\n","print(annotated_lyrics[0]['input_ids'])\n","print(annotated_lyrics[0]['token_type_ids'])\n","print(annotated_lyrics[0]['attention_mask'])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EPL3aOJoxa7Z"},"outputs":[],"source":["dict = {'input_ids': annotated_lyrics_input_ids, 'token_type_ids': annotated_lyrics_token_type_ids, 'attention_mask': annotated_lyrics_attention_mask, 'chords_id': annotated_chords_chords_id}\n","df = pd.DataFrame(dict)\n","df.to_csv('annotated_data.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9447,"status":"ok","timestamp":1697458755230,"user":{"displayName":"Amit Tal","userId":"10134168706322622051"},"user_tz":-180},"id":"dEgv-gZ86x1Z","outputId":"911482fc-a715-45fb-f6ad-649b48035caf"},"outputs":[{"name":"stdout","output_type":"stream","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 40708\n","    })\n","    val: Dataset({\n","        features: ['input_ids', 'attention_mask', 'labels'],\n","        num_rows: 10178\n","    })\n","})\n","{'input_ids': tensor([[ 101, 1030, 1030,  ...,    0,    0,    0],\n","        [ 101, 1030, 1030,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[  0,  26,   0,  ...,   0,   0,   0],\n","        [  0,   0, 170,  ...,   0,   0,   0]])}\n","40708\n","{'input_ids': tensor([  101,  1030,  1030,  7893,  1015,  1024,  1030,  1045,  2196,  2354,\n","         2151,  2028,  2450,  1005,  1055,  2293,  1030,  6561,  2091,  1999,\n","         2026,  2540,  1006,  2126,  2091,  1007,  1010,  8769,  2039,  2026,\n","         3969,  1010,  1030,  1030,  1030,  2507,  2009,  2039,  3336,  1010,\n","         3336,  1010,  2507,  2009,  2039,  1012,  1030,  1006,  1045,  2056,\n","         3336,  2507,  2009,  2039,  1007,  1030,  2507,  2009,  2039,  3336,\n","         1010,  3336,  1010,  2507,  2009,  2039,  1012,  1030,  1006,  1045,\n","         2056,  3336,  2507,  2009,  2039,  1007,  1030,  1045,  1005,  1049,\n","         2746,  2067,  2005,  2062,  1010,  2061,  2330,  2039,  2115,  2341,\n","         1010,  1051, 11631,  3336,  1012,  1030,  1045,  2288,  2019,  2412,\n","         3201,  2293,  1010, 25391,  1010,  2040,  2080,  1011,  1051, 11631,\n","         3336,  1012,  1030,  1045,  2288,  2019,  2412,  3201,  2293,  1012,\n","         1030,  7893,  1016,  1024,  1030,  2129,  2106,  1045,  2412,  2104,\n","         4355, 21499,  1030,  2043,  1010,  9548,  1010,  9044,  2013,  9044,\n","         1010,  1045,  6449,  1045,  1005,  2310,  2179,   102,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   78, 7985,\n","           0,    0, 8050,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,   78, 7985,    0,    0, 8050,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0, 2199,   13,    0,   78,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,   78,    0,    0,\n","           0,    0,   13,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,   78,    0,    0,    0,    0,   13,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,   78, 7985,    0,    0, 8050,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          78, 7985,    0,    0, 8050,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0, 2199,   13,    0,   78,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,   78,    0,    0,    0,    0,   13,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,   78,    0,    0,\n","           0,    0,   13,    0,    0,   78,    0,    0,    0,    0,   78,    0,\n","           0,    0,    0,    0,    0,   78, 7985,    0,    0, 8050,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,   78, 7985,    0,    0, 8050,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 2199,   13,\n","           0,   78,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          78,    0,    0,    0,    0,   13,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,   78,    0,    0,    0,    0,\n","          13,    0,    0,    0,    0,    0,    0,   78,    0,    0,    0,    0,\n","           0,    0,    0,   78,    0,    0,    0,    0,    0,    0,    0,   13,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0])}\n","10178\n"]}],"source":["#DATA = load_dataset(\"csv\", \"annotated_data\")\n","dataset = Dataset.from_pandas(pd.DataFrame(data=data))\n","#DATA = Dataset.from_list(annotated_lyrics_input_ids)\n","dataset = dataset.remove_columns([\"token_type_ids\"])\n","dataset.set_format(\"torch\")\n","dataset = DatasetDict(\n","    train=dataset.shuffle(seed=1111).select(range(int(0.8*len(dataset)))),\n","    val=dataset.shuffle(seed=1111).select(range(int(0.8*len(dataset)), len(dataset)))\n",")\n","print(dataset)\n","print(dataset['train'][0:2])\n","print(len(dataset['train']))\n","print(dataset['val'][0])\n","print(len(dataset['val']))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11764,"status":"ok","timestamp":1697458766984,"user":{"displayName":"Amit Tal","userId":"10134168706322622051"},"user_tz":-180},"id":"YZ8718aLDCCo","outputId":"3f8a8e43-1eb1-4e6b-a1ea-35b55caf2247"},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using a model of type bert to instantiate a model of type distilbert. This is not supported for all configurations of models and can yield errors.\n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['transformer.layer.10.sa_layer_norm.weight', 'transformer.layer.7.attention.q_lin.weight', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.3.attention.k_lin.weight', 'transformer.layer.5.ffn.lin2.weight', 'transformer.layer.6.sa_layer_norm.bias', 'transformer.layer.9.sa_layer_norm.weight', 'transformer.layer.3.output_layer_norm.bias', 'transformer.layer.5.attention.out_lin.bias', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.5.output_layer_norm.bias', 'transformer.layer.11.sa_layer_norm.bias', 'transformer.layer.3.attention.k_lin.bias', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.2.ffn.lin2.weight', 'transformer.layer.5.ffn.lin1.bias', 'transformer.layer.7.output_layer_norm.weight', 'transformer.layer.6.attention.v_lin.bias', 'transformer.layer.11.attention.out_lin.weight', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.8.attention.k_lin.weight', 'transformer.layer.9.attention.k_lin.bias', 'transformer.layer.7.ffn.lin2.bias', 'embeddings.position_embeddings.weight', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.7.sa_layer_norm.weight', 'transformer.layer.7.attention.out_lin.bias', 'transformer.layer.6.ffn.lin2.weight', 'transformer.layer.11.attention.k_lin.bias', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.0.attention.q_lin.weight', 'transformer.layer.10.attention.q_lin.weight', 'classifier.bias', 'transformer.layer.1.attention.v_lin.bias', 'embeddings.word_embeddings.weight', 'transformer.layer.5.ffn.lin2.bias', 'transformer.layer.4.attention.q_lin.bias', 'transformer.layer.6.attention.q_lin.bias', 'transformer.layer.9.ffn.lin1.weight', 'transformer.layer.10.attention.v_lin.bias', 'transformer.layer.10.attention.k_lin.weight', 'transformer.layer.10.sa_layer_norm.bias', 'transformer.layer.10.output_layer_norm.bias', 'transformer.layer.11.attention.v_lin.weight', 'transformer.layer.10.attention.v_lin.weight', 'transformer.layer.6.sa_layer_norm.weight', 'transformer.layer.6.ffn.lin1.weight', 'transformer.layer.2.attention.out_lin.bias', 'transformer.layer.4.ffn.lin2.bias', 'transformer.layer.8.attention.v_lin.weight', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.1.attention.out_lin.bias', 'transformer.layer.11.attention.v_lin.bias', 'transformer.layer.3.attention.out_lin.bias', 'transformer.layer.3.attention.out_lin.weight', 'transformer.layer.7.ffn.lin2.weight', 'transformer.layer.4.attention.out_lin.weight', 'transformer.layer.8.attention.out_lin.weight', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.9.sa_layer_norm.bias', 'transformer.layer.5.attention.out_lin.weight', 'transformer.layer.11.ffn.lin2.bias', 'transformer.layer.7.attention.v_lin.weight', 'transformer.layer.8.attention.q_lin.weight', 'transformer.layer.5.output_layer_norm.weight', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.7.ffn.lin1.bias', 'transformer.layer.3.attention.q_lin.bias', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.4.attention.v_lin.bias', 'transformer.layer.8.attention.v_lin.bias', 'transformer.layer.11.attention.out_lin.bias', 'transformer.layer.10.attention.k_lin.bias', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.2.ffn.lin1.weight', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.8.ffn.lin1.weight', 'transformer.layer.7.ffn.lin1.weight', 'transformer.layer.9.attention.out_lin.weight', 'transformer.layer.11.output_layer_norm.bias', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.9.attention.v_lin.bias', 'transformer.layer.3.ffn.lin2.bias', 'transformer.layer.9.attention.k_lin.weight', 'transformer.layer.8.attention.k_lin.bias', 'transformer.layer.3.ffn.lin1.weight', 'embeddings.LayerNorm.weight', 'transformer.layer.4.attention.k_lin.bias', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.4.attention.v_lin.weight', 'transformer.layer.7.attention.k_lin.weight', 'transformer.layer.5.attention.k_lin.bias', 'transformer.layer.10.attention.q_lin.bias', 'transformer.layer.2.output_layer_norm.bias', 'transformer.layer.6.attention.out_lin.weight', 'transformer.layer.2.sa_layer_norm.weight', 'transformer.layer.10.attention.out_lin.weight', 'transformer.layer.0.attention.v_lin.bias', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.3.sa_layer_norm.bias', 'transformer.layer.8.attention.out_lin.bias', 'transformer.layer.8.output_layer_norm.bias', 'transformer.layer.10.ffn.lin2.weight', 'transformer.layer.5.attention.q_lin.bias', 'transformer.layer.6.output_layer_norm.weight', 'transformer.layer.11.ffn.lin1.bias', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.11.attention.q_lin.bias', 'embeddings.LayerNorm.bias', 'transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.6.attention.k_lin.weight', 'transformer.layer.6.attention.v_lin.weight', 'transformer.layer.9.attention.q_lin.weight', 'transformer.layer.5.attention.v_lin.bias', 'transformer.layer.7.attention.q_lin.bias', 'transformer.layer.5.sa_layer_norm.weight', 'transformer.layer.11.attention.q_lin.weight', 'transformer.layer.11.output_layer_norm.weight', 'transformer.layer.7.attention.v_lin.bias', 'transformer.layer.8.ffn.lin2.weight', 'transformer.layer.8.ffn.lin2.bias', 'transformer.layer.9.output_layer_norm.bias', 'transformer.layer.6.attention.q_lin.weight', 'transformer.layer.6.attention.k_lin.bias', 'classifier.weight', 'transformer.layer.9.output_layer_norm.weight', 'transformer.layer.2.attention.v_lin.weight', 'transformer.layer.4.ffn.lin1.bias', 'transformer.layer.5.attention.q_lin.weight', 'transformer.layer.10.ffn.lin1.weight', 'transformer.layer.7.sa_layer_norm.bias', 'transformer.layer.3.ffn.lin2.weight', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.2.attention.out_lin.weight', 'transformer.layer.5.attention.k_lin.weight', 'transformer.layer.8.sa_layer_norm.bias', 'transformer.layer.9.attention.q_lin.bias', 'transformer.layer.10.output_layer_norm.weight', 'transformer.layer.9.attention.v_lin.weight', 'transformer.layer.11.ffn.lin1.weight', 'transformer.layer.10.ffn.lin2.bias', 'transformer.layer.3.attention.q_lin.weight', 'transformer.layer.9.ffn.lin1.bias', 'transformer.layer.3.output_layer_norm.weight', 'transformer.layer.5.sa_layer_norm.bias', 'transformer.layer.3.attention.v_lin.bias', 'transformer.layer.1.sa_layer_norm.weight', 'transformer.layer.11.sa_layer_norm.weight', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.9.attention.out_lin.bias', 'transformer.layer.11.attention.k_lin.weight', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.8.ffn.lin1.bias', 'transformer.layer.10.attention.out_lin.bias', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.4.attention.out_lin.bias', 'transformer.layer.4.sa_layer_norm.weight', 'transformer.layer.6.output_layer_norm.bias', 'transformer.layer.4.sa_layer_norm.bias', 'transformer.layer.4.output_layer_norm.weight', 'transformer.layer.6.ffn.lin1.bias', 'transformer.layer.0.ffn.lin1.bias', 'transformer.layer.11.ffn.lin2.weight', 'transformer.layer.3.attention.v_lin.weight', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.4.attention.q_lin.weight', 'transformer.layer.8.sa_layer_norm.weight', 'transformer.layer.4.attention.k_lin.weight', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.5.ffn.lin1.weight', 'transformer.layer.10.ffn.lin1.bias', 'transformer.layer.8.attention.q_lin.bias', 'transformer.layer.2.attention.k_lin.bias', 'transformer.layer.4.ffn.lin2.weight', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.6.ffn.lin2.bias', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.3.ffn.lin1.bias', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.9.ffn.lin2.bias', 'transformer.layer.8.output_layer_norm.weight', 'transformer.layer.3.sa_layer_norm.weight', 'transformer.layer.4.output_layer_norm.bias', 'transformer.layer.5.attention.v_lin.weight', 'transformer.layer.9.ffn.lin2.weight', 'transformer.layer.7.attention.out_lin.weight', 'transformer.layer.4.ffn.lin1.weight', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.6.attention.out_lin.bias', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.7.attention.k_lin.bias', 'transformer.layer.7.output_layer_norm.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["124615393\n"]}],"source":["class BERT_For_Chords(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 output_dim,\n","                 dropout = 0,\n","                 dim = 1,\n","                 hidden_layer_size = 300,\n","                 activation = nn.ReLU()):\n","\n","        super().__init__()\n","\n","        self.bert = bert\n","\n","        embedding_dim = bert.config.to_dict()['hidden_size']\n","\n","        self.fc1 =  nn.Sequential(nn.Linear(embedding_dim, hidden_layer_size), activation)\n","\n","        self.hidden_layers = nn.Sequential(*[nn.Linear(hidden_layer_size, hidden_layer_size), activation]*dim)\n","\n","        self.fc2 = nn.Linear(hidden_layer_size, output_dim)\n","\n","        #self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, text, attention_mask):\n","\n","        #text = [sent len, batch size]\n","\n","        text = text.permute(1, 0)\n","        attention_mask = attention_mask.permute(1, 0)\n","\n","        #text = [batch size, sent len]\n","\n","        #embedded = self.dropout(self.bert(text, attention_mask)[0])\n","        embedded = self.bert(text, attention_mask)[0]\n","\n","        #embedded = [batch size, seq len, emb dim]\n","\n","        embedded = embedded.permute(1, 0, 2)\n","\n","        #embedded = [sent len, batch size, emb dim]\n","\n","        #predictions = self.fc1(self.dropout(embedded))\n","\n","        #predictions = self.hidden_layers(self.dropout(predictions))\n","\n","        #predictions = self.fc2(self.dropout(predictions))\n","\n","        predictions = self.fc1(embedded)\n","\n","        predictions = self.hidden_layers(predictions)\n","\n","        predictions = self.fc2(predictions)\n","\n","        #predictions = [sent len, batch size, output dim]\n","\n","        return predictions\n","\n","\n","NOTES_NUM = 12\n","CHORD_TYPES_NUM = 142\n","OUTPUT_DIM = 1+CHORD_TYPES_NUM*NOTES_NUM**2\n","DROPOUT = 0.25\n","dim = 4\n","hidden_layer_size = 300\n","activation = nn.ReLU()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","bert = BertModel.from_pretrained('bert-base-uncased').to(device)\n","\n","\n","#model = BERT_For_Chords(bert, OUTPUT_DIM, DROPOUT, dim,hidden_layer_size, activation)\n","\n","model = DistilBertForTokenClassification.from_pretrained(\n","    'bert-base-uncased',\n","    num_labels = OUTPUT_DIM,\n","    output_attentions = False,\n","    output_hidden_states = False,\n","    )\n","model.to(device)\n","print(model.num_parameters())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hWPWMheVXS8R"},"outputs":[],"source":["\n","def b_tp(preds, labels):\n","  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n","  return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n","\n","def b_fp(preds, labels):\n","  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n","  return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n","\n","def b_tn(preds, labels):\n","  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n","  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n","\n","def b_fn(preds, labels):\n","  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n","  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n","\n","def b_metrics(preds, labels):\n","  '''\n","  Returns the following metrics:\n","    - accuracy    = (TP + TN) / N\n","    - precision   = TP / (TP + FP)\n","    - recall      = TP / (TP + FN)\n","    - specificity = TN / (TN + FP)\n","  '''\n","  preds = np.argmax(preds, axis = 1).flatten()\n","  labels = labels.flatten()\n","  tp = b_tp(preds, labels)\n","  tn = b_tn(preds, labels)\n","  fp = b_fp(preds, labels)\n","  fn = b_fn(preds, labels)\n","  b_accuracy = (tp + tn) / len(labels)\n","  b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n","  b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n","  b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n","  return b_accuracy, b_precision, b_recall, b_specificity"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PnrUOCL8WoKT","outputId":"01a5cf18-0eac-4f8d-8ee7-a5023e50a0ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["starting epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-16-9d475806ee19>\", line 70, in <cell line: 11>\n","    if val_accuracy < best_val_accuracy:\n","TypeError: '<' not supported between instances of 'list' and 'float'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-16-9d475806ee19>\", line 70, in <cell line: 11>\n","    if val_accuracy < best_val_accuracy:\n","TypeError: '<' not supported between instances of 'list' and 'float'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-16-9d475806ee19>\", line 70, in <cell line: 11>\n","    if val_accuracy < best_val_accuracy:\n","TypeError: '<' not supported between instances of 'list' and 'float'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n","    self.showtraceback()\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n","    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n"]}],"source":["optimizer = torch.optim.AdamW(model.parameters(),\n","                              lr = 5e-5,\n","                              eps = 1e-08\n","                              )\n","BATCH_SIZE = 8\n","train_dataloader = DataLoader(dataset['train'], batch_size=BATCH_SIZE)\n","eval_dataloader = DataLoader(dataset['val'], batch_size=BATCH_SIZE)\n","N_EPOCHS = 5\n","best_val_accuracy = float(\"inf\")\n","\n","for epoch in range(N_EPOCHS):\n","    print(f\"starting epoch {epoch}\")\n","\n","    # ========== Training ==========\n","\n","    # Set model to training mode\n","    model.train()\n","\n","    # Tracking variables\n","    tr_loss = 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","\n","    for step, batch in enumerate(train_dataloader):\n","        b_input_ids = batch['input_ids'].to(device)\n","        b_input_mask = batch['attention_mask'].to(device)\n","        b_labels = batch['labels'].to(device)\n","        optimizer.zero_grad()\n","        # Forward pass\n","        train_output = model(b_input_ids,\n","                             attention_mask = b_input_mask,\n","                             labels = b_labels)\n","        # Backward pass\n","        train_output.loss.backward()\n","        optimizer.step()\n","        # Update tracking variables\n","        tr_loss += train_output.loss.item()\n","        nb_tr_examples += b_input_ids.size(0)\n","        nb_tr_steps += 1\n","\n","    # ========== Validation ==========\n","\n","    # Set model to evaluation mode\n","    model.eval()\n","\n","    # Tracking variables\n","    val_accuracy = []\n","    val_precision = []\n","    val_recall = []\n","    val_specificity = []\n","\n","    for batch_i, batch in enumerate(eval_dataloader):\n","        b_input_ids = batch['input_ids'].to(device)\n","        b_input_mask = batch['attention_mask'].to(device)\n","        b_labels = batch['labels'].to(device)\n","        with torch.no_grad():\n","          # Forward pass\n","          eval_output = model(b_input_ids,\n","                              attention_mask = b_input_mask)\n","        logits = eval_output.logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        # Calculate validation metrics\n","        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n","        val_accuracy.append(b_accuracy)\n","        # Update precision only when (tp + fp) !=0; ignore nan\n","        if b_precision != 'nan': val_precision.append(b_precision)\n","        # Update recall only when (tp + fn) !=0; ignore nan\n","        if b_recall != 'nan': val_recall.append(b_recall)\n","        # Update specificity only when (tn + fp) !=0; ignore nan\n","        if b_specificity != 'nan': val_specificity.append(b_specificity)\n","    if val_accuracy < best_val_accuracy:\n","      best_val_accuracy = val_accuracy\n","      print(\"Saving checkpoint!\")\n","      torch.save({\n","          'epoch': epoch,\n","          'model_state_dict': model.state_dict(),\n","          'optimizer_state_dict': optimizer.state_dict(),\n","          'val_accuracy': val_accuracy,\n","          },\n","          f\"checkpoints/epoch_{epoch}.pt\"\n","      )\n","\n","    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n","    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n","    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n","    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n","    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3847,"status":"ok","timestamp":1697464453654,"user":{"displayName":"Amit Tal","userId":"10134168706322622051"},"user_tz":-180},"id":"WtT135QUqnf5","outputId":"aa6d3951-a84c-4a95-dcec-fd70ddfd8b2a"},"outputs":[{"name":"stderr","output_type":"stream","text":["You are using a model of type bert to instantiate a model of type distilbert. This is not supported for all configurations of models and can yield errors.\n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['transformer.layer.10.sa_layer_norm.weight', 'transformer.layer.7.attention.q_lin.weight', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.3.attention.k_lin.weight', 'transformer.layer.5.ffn.lin2.weight', 'transformer.layer.6.sa_layer_norm.bias', 'transformer.layer.9.sa_layer_norm.weight', 'transformer.layer.3.output_layer_norm.bias', 'transformer.layer.5.attention.out_lin.bias', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.5.output_layer_norm.bias', 'transformer.layer.11.sa_layer_norm.bias', 'transformer.layer.3.attention.k_lin.bias', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.2.ffn.lin2.weight', 'transformer.layer.5.ffn.lin1.bias', 'transformer.layer.7.output_layer_norm.weight', 'transformer.layer.6.attention.v_lin.bias', 'transformer.layer.11.attention.out_lin.weight', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.8.attention.k_lin.weight', 'transformer.layer.9.attention.k_lin.bias', 'transformer.layer.7.ffn.lin2.bias', 'embeddings.position_embeddings.weight', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.7.sa_layer_norm.weight', 'transformer.layer.7.attention.out_lin.bias', 'transformer.layer.6.ffn.lin2.weight', 'transformer.layer.11.attention.k_lin.bias', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.0.attention.q_lin.weight', 'transformer.layer.10.attention.q_lin.weight', 'classifier.bias', 'transformer.layer.1.attention.v_lin.bias', 'embeddings.word_embeddings.weight', 'transformer.layer.5.ffn.lin2.bias', 'transformer.layer.4.attention.q_lin.bias', 'transformer.layer.6.attention.q_lin.bias', 'transformer.layer.9.ffn.lin1.weight', 'transformer.layer.10.attention.v_lin.bias', 'transformer.layer.10.attention.k_lin.weight', 'transformer.layer.10.sa_layer_norm.bias', 'transformer.layer.10.output_layer_norm.bias', 'transformer.layer.11.attention.v_lin.weight', 'transformer.layer.10.attention.v_lin.weight', 'transformer.layer.6.sa_layer_norm.weight', 'transformer.layer.6.ffn.lin1.weight', 'transformer.layer.2.attention.out_lin.bias', 'transformer.layer.4.ffn.lin2.bias', 'transformer.layer.8.attention.v_lin.weight', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.1.attention.out_lin.bias', 'transformer.layer.11.attention.v_lin.bias', 'transformer.layer.3.attention.out_lin.bias', 'transformer.layer.3.attention.out_lin.weight', 'transformer.layer.7.ffn.lin2.weight', 'transformer.layer.4.attention.out_lin.weight', 'transformer.layer.8.attention.out_lin.weight', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.9.sa_layer_norm.bias', 'transformer.layer.5.attention.out_lin.weight', 'transformer.layer.11.ffn.lin2.bias', 'transformer.layer.7.attention.v_lin.weight', 'transformer.layer.8.attention.q_lin.weight', 'transformer.layer.5.output_layer_norm.weight', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.7.ffn.lin1.bias', 'transformer.layer.3.attention.q_lin.bias', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.4.attention.v_lin.bias', 'transformer.layer.8.attention.v_lin.bias', 'transformer.layer.11.attention.out_lin.bias', 'transformer.layer.10.attention.k_lin.bias', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.2.ffn.lin1.weight', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.8.ffn.lin1.weight', 'transformer.layer.7.ffn.lin1.weight', 'transformer.layer.9.attention.out_lin.weight', 'transformer.layer.11.output_layer_norm.bias', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.9.attention.v_lin.bias', 'transformer.layer.3.ffn.lin2.bias', 'transformer.layer.9.attention.k_lin.weight', 'transformer.layer.8.attention.k_lin.bias', 'transformer.layer.3.ffn.lin1.weight', 'embeddings.LayerNorm.weight', 'transformer.layer.4.attention.k_lin.bias', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.4.attention.v_lin.weight', 'transformer.layer.7.attention.k_lin.weight', 'transformer.layer.5.attention.k_lin.bias', 'transformer.layer.10.attention.q_lin.bias', 'transformer.layer.2.output_layer_norm.bias', 'transformer.layer.6.attention.out_lin.weight', 'transformer.layer.2.sa_layer_norm.weight', 'transformer.layer.10.attention.out_lin.weight', 'transformer.layer.0.attention.v_lin.bias', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.3.sa_layer_norm.bias', 'transformer.layer.8.attention.out_lin.bias', 'transformer.layer.8.output_layer_norm.bias', 'transformer.layer.10.ffn.lin2.weight', 'transformer.layer.5.attention.q_lin.bias', 'transformer.layer.6.output_layer_norm.weight', 'transformer.layer.11.ffn.lin1.bias', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.11.attention.q_lin.bias', 'embeddings.LayerNorm.bias', 'transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.6.attention.k_lin.weight', 'transformer.layer.6.attention.v_lin.weight', 'transformer.layer.9.attention.q_lin.weight', 'transformer.layer.5.attention.v_lin.bias', 'transformer.layer.7.attention.q_lin.bias', 'transformer.layer.5.sa_layer_norm.weight', 'transformer.layer.11.attention.q_lin.weight', 'transformer.layer.11.output_layer_norm.weight', 'transformer.layer.7.attention.v_lin.bias', 'transformer.layer.8.ffn.lin2.weight', 'transformer.layer.8.ffn.lin2.bias', 'transformer.layer.9.output_layer_norm.bias', 'transformer.layer.6.attention.q_lin.weight', 'transformer.layer.6.attention.k_lin.bias', 'classifier.weight', 'transformer.layer.9.output_layer_norm.weight', 'transformer.layer.2.attention.v_lin.weight', 'transformer.layer.4.ffn.lin1.bias', 'transformer.layer.5.attention.q_lin.weight', 'transformer.layer.10.ffn.lin1.weight', 'transformer.layer.7.sa_layer_norm.bias', 'transformer.layer.3.ffn.lin2.weight', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.2.attention.out_lin.weight', 'transformer.layer.5.attention.k_lin.weight', 'transformer.layer.8.sa_layer_norm.bias', 'transformer.layer.9.attention.q_lin.bias', 'transformer.layer.10.output_layer_norm.weight', 'transformer.layer.9.attention.v_lin.weight', 'transformer.layer.11.ffn.lin1.weight', 'transformer.layer.10.ffn.lin2.bias', 'transformer.layer.3.attention.q_lin.weight', 'transformer.layer.9.ffn.lin1.bias', 'transformer.layer.3.output_layer_norm.weight', 'transformer.layer.5.sa_layer_norm.bias', 'transformer.layer.3.attention.v_lin.bias', 'transformer.layer.1.sa_layer_norm.weight', 'transformer.layer.11.sa_layer_norm.weight', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.9.attention.out_lin.bias', 'transformer.layer.11.attention.k_lin.weight', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.8.ffn.lin1.bias', 'transformer.layer.10.attention.out_lin.bias', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.4.attention.out_lin.bias', 'transformer.layer.4.sa_layer_norm.weight', 'transformer.layer.6.output_layer_norm.bias', 'transformer.layer.4.sa_layer_norm.bias', 'transformer.layer.4.output_layer_norm.weight', 'transformer.layer.6.ffn.lin1.bias', 'transformer.layer.0.ffn.lin1.bias', 'transformer.layer.11.ffn.lin2.weight', 'transformer.layer.3.attention.v_lin.weight', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.4.attention.q_lin.weight', 'transformer.layer.8.sa_layer_norm.weight', 'transformer.layer.4.attention.k_lin.weight', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.5.ffn.lin1.weight', 'transformer.layer.10.ffn.lin1.bias', 'transformer.layer.8.attention.q_lin.bias', 'transformer.layer.2.attention.k_lin.bias', 'transformer.layer.4.ffn.lin2.weight', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.6.ffn.lin2.bias', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.3.ffn.lin1.bias', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.9.ffn.lin2.bias', 'transformer.layer.8.output_layer_norm.weight', 'transformer.layer.3.sa_layer_norm.weight', 'transformer.layer.4.output_layer_norm.bias', 'transformer.layer.5.attention.v_lin.weight', 'transformer.layer.9.ffn.lin2.weight', 'transformer.layer.7.attention.out_lin.weight', 'transformer.layer.4.ffn.lin1.weight', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.6.attention.out_lin.bias', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.7.attention.k_lin.bias', 'transformer.layer.7.output_layer_norm.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["no model for checkpoints 0\n","no model for checkpoints 1\n","no model for checkpoints 2\n","no model for checkpoints 3\n","no model for checkpoints 4\n"]},{"data":{"text/plain":["DistilBertForTokenClassification(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0-11): 12 x TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            (activation): GELUActivation()\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=20449, bias=True)\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["NOTES_NUM = 12\n","CHORD_TYPES_NUM = 142\n","OUTPUT_DIM = 1+CHORD_TYPES_NUM*NOTES_NUM**2\n","model = DistilBertForTokenClassification.from_pretrained(\n","    'bert-base-uncased',\n","    num_labels = OUTPUT_DIM,\n","    output_attentions = False,\n","    output_hidden_states = False,\n","    )\n","optimizer = torch.optim.AdamW(model.parameters(),\n","                              lr = 5e-5,\n","                              eps = 1e-08\n","                              )\n","\n","for i in range(N_EPOCHS):\n","  try:\n","    checkpoint = torch.load(f\"checkpoints/epoch_{i}.pt\", map_location='cpu')\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    print(f\"load model for checkpoints {i}\")\n","  except:\n","    print(f\"no model for checkpoints {i}\")\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vf-V40AJx9xO"},"outputs":[],"source":["#https://www.song-lyrics-generator.org.uk/\n","song = '''We're all going to a summer road trip\n"," @ No more shouting for a week or two\n"," @ Super bananas and ugly ants at our summer road trip\n"," @ No more meaty ants for me or you\n"," @ For a week or two\n","\n"," @ Summertime, and the livin' is super\n"," @ Bananas are bouncing and the ants are high\n"," @ Oh, your brother-in-laws smelly and your instructor is bright\n"," @ So hush my crazy dearest, don't you cry\n","\n"," @ Oh the summer of 2000\n","\n"," @ I cant wait to do some bouncing with you\n"," @ You cant wait to do some bouncing with me\n"," @ This just cant be summer love, youll see\n"," @ This just cant be summer love\n","\n"," @ Cause you were mine for the summer\n"," @ Now we know its nearly over\n"," @ Feels like Sunday mist\n"," @ But I always will remember\n"," @ You were my summer love\n"," @ You always will be my summer love\n","\n"," @ I wish they all could be\n"," @ I wish they all could be\n"," @ I wish they all could be bananas of Canada\n","\n"," @ Summertime, and the livin is super\n"," @ Bananas are bouncing and the ants are high\n"," @ Oh, your brother-in-law's smelly and your instructor is bright\n"," @ So hush crazy dearest, don't you cry\n","\n"," @ Me and some ants from Skegness\n"," @ Had a band and we tried real hard.\n"," @ Arthur quit, Lisa went daring\n"," @ I should've known we'd never end up collapsing\n","\n"," @ Oh the summer of 2000\n","\n"," @ Summer bouncing had me a blast, oh yeah\n"," @ Summer bouncing happened so fast,\n","\n"," @ Summer road trip drifting away,\n"," @ To, uh oh, that summer road trip\n","\n"," @ Yeah the summer of 2000'''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1697464453654,"user":{"displayName":"Amit Tal","userId":"10134168706322622051"},"user_tz":-180},"id":"OISN8obkzeCP","outputId":"1ef26ab6-c501-4d7d-e45d-8cfd10b8637f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 8717  7927 14222   479  1148  8762  1188 19271   605  8537  7752 13394\n","   561  9924 13945  5986  9991  1485 15716  4282  4460  7571  9612  2401\n"," 13433 20059  6360 10399 16957  5013  2949  3189 10052 12535  1188 14751\n"," 19481  3334  2165 12025  7347  4156 10381 13467 19319 19526 13875 14965\n"," 19658  6807 10666   682  5710  3047 18343   125 15227 10171 12316  5353\n"," 11256  4625 15091 18443  6842  3917 17295 15529 12316 12405 19904  3189\n","  7189 15651  5687 16033  3182  2374 15918  5099 10665   381 14469 14152\n"," 20087 17361  7044  4140 13310  3170 15702  5416   125  4965 15970  9593\n"," 16957 12666 15684  2893  3189  3919 12316  3276   253 16232  9922  5391\n","   125 12025 18770 13486 17454  9811 16245  6086   461 10818 13891  7571\n"," 13624 15447  4492  2165  2923 14770 12989  4445 17945   564  5262  4140\n","   461  2301  6343   247 17777 20221 11992  9334 14286 18375  4111 18041\n"," 16095  8822  6678 13479  2401 19206  8244 14680  5941  6674 18841  9704\n"," 12902  5262  9704 10893    24 17175  6409  3778 19493 17503 16035 16663\n"," 13954 10201 12645  1223  1485  2848 10201  6390  5266  8789 16198 19408\n"," 17342 19168  7571 14948  5812 12566  8370   387  9562  3047 10279   730\n","   791 16865  7235 14827 11259  1368 12427  1188 12534 12073 13525  7090\n","  5972 20050 15765 13301 19568 15091  5109  4748 10277 11179 13394 19619\n","  1951 11930   581  7685 15823 20221  7832 15838   964 10231 18169 13837\n","  9283   984  8053   134   294  6914  6531 13086  2773  2654 11002 11859\n"," 20221 11990  4749  8537  1849   545 14681 14509 13368    33 14387 15299\n"," 12069 14900  7535 12263  9218 13301  8717 20320  1380  9699 13070  1154\n","  5055  5817    32 12200  1154 15725 13858  7792 13596  1882  3997  1173\n"," 15953  5013 20221 10818  5725  5986  5635 12713 16095 11013  3125  2361\n","  3508 10381 20420 13394 12383  9894  7675 20388  9164  4845  3201   499\n","  2219  9997 13310 20183  1107 15584 15532  3215  8091 10733 15256  9969\n","  7863 10703  9078  4396 20353 12911 16095  2923  4748 20169  7675 13485\n","  4696  4140 13467  9164 11510 10347 17691 20050  6542  8332 12383   984\n"," 15685  5377 14263 14895   134 13654 18073  8171 15124  1218  9312   134\n","  4046 10784  2395    83  1498 11261 16957 13101   134  7712  1243  9102\n","  2919  6531 11870 17413 16752  9630 17094 11126  9078   365 17655 13301\n"," 15885  5154  1625  2037  3201  8649 19498 15731 18465 12892   263 12256\n"," 10387 14412 14801  8687  4156  4443 17162  7864  7419  9894  9897  5601\n"," 13718  3349   620 12200 13551 20438  2291  7562 15033 16500 11126 16075\n","  2723 12185   226 12264 16695  5986   743  7316  7999 10818  4965 10300\n"," 13944  7220  9164  9230 12734  8228  5619 12666 15931  3276 11139  1318\n","  7190 15447 16596   632  4156  7277   984   545  8822  6182 11260 16868\n","   447 13526  5013  1368  9704  2824 11737 13654 10831 16893  3519 11202\n","  3722  4156  7222 13385 16492 19671  9283 16492   253  5154  6427  1498\n","  5329  3303  1658 18662  9639 17315  7907 11024  3529 16957 16957 17778\n","  7467 20120  9102 12898 18590 10349 13385 12898  7920  1498 19852  7947\n"," 13654  9305 11652  9558 18150  4515 19808  6678 10212 15716 11257 13208\n"," 10525 12933 15091  6873 18134  3349 12831 16492]\n"]}],"source":["tokenized_song = tokenizer(cut_to_max_length(song, max_input_length),\n","                         padding='max_length',\n","                         truncation=True)\n","\n","input_ids = torch.IntTensor(tokenized_song['input_ids'])\n","input_ids = torch.reshape(input_ids, (1, -1))\n","\n","token_type_ids = torch.IntTensor(tokenized_song['token_type_ids'])\n","token_type_ids = torch.reshape(token_type_ids, (1, -1))\n","\n","attention_mask = torch.IntTensor(tokenized_song['attention_mask'])\n","attention_mask = torch.reshape(attention_mask, (1, -1))\n","\n","song_chords = model(input_ids.to(device), attention_mask.to(device)).logits\n","song_chords = torch.reshape(song_chords, (max_input_length, -1))\n","song_chords = song_chords.argmax(1)\n","song_chords = np.array(song_chords.tolist())\n","print(song_chords)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1697464453654,"user":{"displayName":"Amit Tal","userId":"10134168706322622051"},"user_tz":-180},"id":"g-xFgV2CEJFx","outputId":"8fdb7e59-bb9c-4b9e-e574-55e28c4b9b94"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nLEARNING_RATE = 5e-5\\nN_EPOCHS = 15\\n\\noptimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\\n\\nTAG_PAD_IDX = 0\\n\\ncriterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\\n\\nBATCH_SIZE = 16\\n\\nmodel = model.to(device)\\ncriterion = criterion.to(device)\\n'"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","LEARNING_RATE = 5e-5\n","N_EPOCHS = 15\n","\n","optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)\n","\n","TAG_PAD_IDX = 0\n","\n","criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n","\n","BATCH_SIZE = 16\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":163},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1697464453655,"user":{"displayName":"Amit Tal","userId":"10134168706322622051"},"user_tz":-180},"id":"c1M1-XxILYmw","outputId":"bf7bd35c-a533-41e0-e64b-9568bb97bc8b"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ntrain_dataloader = DataLoader(dataset[\\'train\\'], batch_size=BATCH_SIZE)\\neval_dataloader = DataLoader(dataset[\\'val\\'], batch_size=BATCH_SIZE)\\nbest_val_loss = float(\"inf\")\\nfor epoch in range(N_EPOCHS):\\n    print(epoch)\\n    # training\\n    model.train()\\n    for batch_i, batch in enumerate(train_dataloader):\\n        if batch_i % 500 == 0:\\n          print(batch_i)\\n        text = batch[\\'input_ids\\']\\n        attention_mask = batch[\\'attention_mask\\']\\n        tags = batch[\\'labels\\']\\n\\n        optimizer.zero_grad()\\n\\n        #text = [sent len, batch size]\\n\\n        predictions = model(text.to(device), attention_mask.to(device))\\n        #predictions = model(text.to(device), token_type_ids = None, attention_mask attention_mask.to(device),labels = tags.view(-1).to(device))\\n\\n        #predictions = [sent len, batch size, output dim]\\n        #tags = [sent len, batch size]\\n\\n        predictions = predictions.view(-1, predictions.shape[-1])\\n        tags = tags.view(-1)\\n\\n        #predictions = [sent len * batch size, output dim]\\n        #tags = [sent len * batch size]\\n\\n        loss = criterion(predictions.to(device), tags.to(device))\\n\\n        loss.backward()\\n\\n        optimizer.step()\\n\\n    # validation\\n    model.eval()\\n    loss = 0\\n    for batch_i, batch in enumerate(eval_dataloader):\\n        if batch_i % 500 == 0:\\n          print(batch_i)\\n        text = batch[\\'input_ids\\']\\n        attention_mask = batch[\\'attention_mask\\']\\n        tags = batch[\\'labels\\']\\n        with torch.no_grad():\\n            predictions = model(text.to(device), attention_mask.to(device))\\n        predictions = predictions.view(-1, predictions.shape[-1])\\n        tags = tags.view(-1)\\n        loss += criterion(predictions.to(device), tags.to(device))\\n\\n    avg_val_loss = loss / len(eval_dataloader)\\n    print(f\"Validation loss: {avg_val_loss}\")\\n    if avg_val_loss < best_val_loss:\\n        print(\"Saving checkpoint!\")\\n        best_val_loss = avg_val_loss\\n        torch.save({\\n            \\'epoch\\': epoch,\\n            \\'model_state_dict\\': model.state_dict(),\\n            \\'optimizer_state_dict\\': optimizer.state_dict(),\\n            \\'val_loss\\': best_val_loss,\\n            },\\n            f\"checkpoints/epoch_{epoch}.pt\"\\n        )\\n'"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","train_dataloader = DataLoader(dataset['train'], batch_size=BATCH_SIZE)\n","eval_dataloader = DataLoader(dataset['val'], batch_size=BATCH_SIZE)\n","best_val_loss = float(\"inf\")\n","for epoch in range(N_EPOCHS):\n","    print(epoch)\n","    # training\n","    model.train()\n","    for batch_i, batch in enumerate(train_dataloader):\n","        if batch_i % 500 == 0:\n","          print(batch_i)\n","        text = batch['input_ids']\n","        attention_mask = batch['attention_mask']\n","        tags = batch['labels']\n","\n","        optimizer.zero_grad()\n","\n","        #text = [sent len, batch size]\n","\n","        predictions = model(text.to(device), attention_mask.to(device))\n","        #predictions = model(text.to(device), token_type_ids = None, attention_mask attention_mask.to(device),labels = tags.view(-1).to(device))\n","\n","        #predictions = [sent len, batch size, output dim]\n","        #tags = [sent len, batch size]\n","\n","        predictions = predictions.view(-1, predictions.shape[-1])\n","        tags = tags.view(-1)\n","\n","        #predictions = [sent len * batch size, output dim]\n","        #tags = [sent len * batch size]\n","\n","        loss = criterion(predictions.to(device), tags.to(device))\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","    # validation\n","    model.eval()\n","    loss = 0\n","    for batch_i, batch in enumerate(eval_dataloader):\n","        if batch_i % 500 == 0:\n","          print(batch_i)\n","        text = batch['input_ids']\n","        attention_mask = batch['attention_mask']\n","        tags = batch['labels']\n","        with torch.no_grad():\n","            predictions = model(text.to(device), attention_mask.to(device))\n","        predictions = predictions.view(-1, predictions.shape[-1])\n","        tags = tags.view(-1)\n","        loss += criterion(predictions.to(device), tags.to(device))\n","\n","    avg_val_loss = loss / len(eval_dataloader)\n","    print(f\"Validation loss: {avg_val_loss}\")\n","    if avg_val_loss < best_val_loss:\n","        print(\"Saving checkpoint!\")\n","        best_val_loss = avg_val_loss\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'val_loss': best_val_loss,\n","            },\n","            f\"checkpoints/epoch_{epoch}.pt\"\n","        )\n","\"\"\""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["EoC7XDIb2ODN"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
